(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{345:function(e,t,r){"use strict";r.r(t);var a=r(4),_=Object(a.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[t("a",{attrs:{href:"https://towardsdatascience.com/transfer-learning-on-greyscale-images-how-to-fine-tune-pretrained-models-on-black-and-white-9a5150755c7a",target:"_blank",rel:"noopener noreferrer"}},[e._v("转载链接"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("随着深度学习领域的不断成熟，此时人们普遍认为迁移学习是计算机视觉快速取得良好结果的关键，尤其是在处理小数据集时。虽然从预训练模型开始的差异部分取决于新数据集与原始训练数据的相似程度，但可以说从预训练模型开始几乎总是有利的。")]),e._v(" "),t("p",[e._v("尽管可用于图像分类任务的预训练模型数量不断增加，但在撰写本文时，其中大多数模型都是在某些版本的"),t("a",{attrs:{href:"https://www.image-net.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ImageNet 数据集"),t("OutboundLink")],1),e._v("上训练的；其中包含彩色图像。虽然这通常是我们正在寻找的东西，但在某些领域——例如制造和医学成像——遇到黑白图像数据集的情况并不少见。")]),e._v(" "),t("p",[e._v("由于彩色图像和黑白图像之间的差异对我们人类来说微不足道，您可能会认为微调预训练模型应该开箱即用，但这种情况很少见。因此，特别是如果您的图像处理背景有限，可能很难知道在这些情况下最好的方法是什么，")]),e._v(" "),t("p",[e._v("在本文中，我们将尝试通过探索 RGB 和灰度图像之间的差异，以及这些格式如何影响卷积神经网络模型完成的处理操作，来揭开微调黑白图像时需要考虑的所有因素的神秘面纱，然后再进行演示如何将灰度图像与预训练模型一起使用。最后，我们将检查在一些开源数据集上探索的不同方法的性能，并将其与从头开始在灰度图像上进行的训练进行比较。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/5e300035655e84a7575f6e391f9451d5.png",alt:""}})]),e._v(" "),t("p",[e._v("图片取自公开可用的"),t("a",{attrs:{href:"https://github.com/AI-Lab-Makerere/ibean/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Beans 数据集"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("虽然彩色和灰度图像可能与我们非常相似，但由于计算机只能将图像视为一组数字，因此这会对图像的解释方式产生巨大的影响！因此，要充分理解为什么灰度图像可能对预训练网络构成挑战，我们必须首先检查计算机解释彩色和灰度图像的方式的差异。")]),e._v(" "),t("p",[e._v("作为示例，让我们使用来自"),t("a",{attrs:{href:"https://github.com/AI-Lab-Makerere/ibean/",target:"_blank",rel:"noopener noreferrer"}},[e._v("beans 数据集"),t("OutboundLink")],1),e._v("的图像。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/50de42455d45a1c097822281381fe615.png",alt:""}})]),e._v(" "),t("h2",{attrs:{id:"rgb图像"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rgb图像"}},[e._v("#")]),e._v(" RGB图像")]),e._v(" "),t("p",[e._v("通常，当我们在深度学习中处理彩色图像时，这些图像以 RGB 格式表示。在高层次上，RGB 是一种加法颜色模型，其中每种颜色都由红色、绿色和蓝色值的组合表示；这些通常存储为单独的“通道”，因此 RGB 图像通常被称为 3 通道图像。")]),e._v(" "),t("p",[e._v("我们可以使用 PIL 检查图像的模式——一个定义图像中像素类型和深度的字符串，如此处所述"),t("a",{attrs:{href:"https://pillow.readthedocs.io/en/latest/handbook/concepts.html#modes",target:"_blank",rel:"noopener noreferrer"}},[e._v("——"),t("OutboundLink")],1),e._v("以及检查可用通道，如下所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/2ba1046c2688116c20d4fd7af1911812.png",alt:""}})]),e._v(" "),t("p",[e._v("这证实 PIL 已将其识别为 RGB 图像。因此，对于每个像素，存储在这些通道中的值（称为强度）均构成整体颜色的一个组成部分。")]),e._v(" "),t("p",[e._v("这些组件可以用不同的方式表示：")]),e._v(" "),t("ul",[t("li",[e._v("最常见的是，组件值存储为 0 到 255 范围内的无符号整数；单个 8 位字节可以提供的范围。")]),e._v(" "),t("li",[e._v("在浮点表示中，值可以表示为 0 到 1，中间可以有任何小数值。")]),e._v(" "),t("li",[e._v("每个颜色分量值也可以写成百分比，从 0% 到 100%。")])]),e._v(" "),t("p",[e._v("将我们的图像转换为 NumPy 数组，我们可以看到，默认情况下，图像表示为无符号整数数组：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/cca922e5f1b789606c43c9e56b2e5f98.png",alt:""}})]),e._v(" "),t("p",[e._v("检查数组的形状，我们可以看到图像有 3 个通道，这符合我们的预期：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/9837262f081dae6c27913d738e20797a.png",alt:""}})]),e._v(" "),t("p",[e._v("要将我们的图像数组转换为浮点表示，我们可以"),t("code",[e._v("dtype")]),e._v("在创建时明确指定数组的 。让我们看看当我们转换和绘制图像时会发生什么。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/bc34ee95058dce205150959a8ff9314a.png",alt:""}})]),e._v(" "),t("p",[e._v("不好了！")]),e._v(" "),t("p",[e._v("从可以通过检查数据确认的警告消息中，我们可以看出图像未正确显示的原因是因为输入数据不在浮点表示的正确范围内。为了纠正这个问题，让我们将数组中的每个元素除以 255；这应该确保每个元素都在 [0, 1] 范围内。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/a78221813fdbbcd16be41c4f55ab9fb0.png",alt:""}})]),e._v(" "),t("p",[e._v("绘制我们的归一化数组，我们可以看到图像现在可以正确显示了！")]),e._v(" "),t("p",[t("strong",[e._v("了解成分强度")])]),e._v(" "),t("p",[e._v("通过调整每个分量的强度，我们可以使用 RGB 模型表示各种颜色。")]),e._v(" "),t("p",[e._v("当组合每个组件的 0% 强度时，不会产生光，因此会产生黑色（最暗的可能颜色）。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/46e59ee37e52b0e63beb379e88dd6b04.png",alt:""}})]),e._v(" "),t("p",[e._v("当所有成分的强度都相同时，结果是灰色阴影，根据强度的大小而变深或变浅。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/38fae6bc761406fe17fde860829089b9.png",alt:""}})]),e._v(" "),t("p",[e._v("当其中一个成分的强度比其他成分强时，生成的颜色更接近具有最强成分（红色、绿色或蓝色）的原色：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/761c16c493e2f10f2f4f6c56edd0b324.png",alt:""}})]),e._v(" "),t("p",[e._v("当每个组件的 100% 强度组合在一起时，就会产生白色（最浅的颜色）。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/00375e57a51110b5687be100222739d0.png",alt:""}})]),e._v(" "),t("p",[e._v("虽然这有望提供 RGB 图像的概述，但可以在"),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/RGB_color_model",target:"_blank",rel:"noopener noreferrer"}},[e._v("此处"),t("OutboundLink")],1),e._v("找到有关 RGB 颜色模型的更多详细信息。")]),e._v(" "),t("h2",{attrs:{id:"灰度图像"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#灰度图像"}},[e._v("#")]),e._v(" 灰度图像")]),e._v(" "),t("p",[e._v("现在我们已经研究了如何使用 RGB 颜色模型表示彩色图像，让我们研究一下灰​​度图像与此有何不同。")]),e._v(" "),t("p",[e._v("灰度图像只是其中唯一表示的颜色是不同灰色阴影的图像。虽然我们在日常对话中经常将此类图像称为“黑白图像”，但真正的“黑白图像”只会由这两种截然不同的颜色组成，这种情况很少见；使“灰度”成为更准确的术语。")]),e._v(" "),t("p",[e._v("由于没有颜色信息来表示灰度图像，因此每个像素需要存储的信息较少，并且不需要加法颜色模型！对于灰度图像，我们唯一需要的信息是一个单一的值来表示每个像素的强度；该值越高，灰色阴影越浅。因此，灰度图像通常由单个通道组成，其中每个像素强度只是一个介于 0 到 255 之间的数字。")]),e._v(" "),t("p",[e._v("为了进一步探索这一点，我们可以使用 PIL 将图像转换为灰度，如下所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/8ac5b391acf6622725a485ab8fcb2beb.png",alt:""}})]),e._v(" "),t("p",[e._v("和以前一样，我们可以使用 PIL 检查模式和图像通道。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/779c1c7080ae04cf5d614c883e296711.png",alt:""}})]),e._v(" "),t("p",[e._v("从"),t("a",{attrs:{href:"https://pillow.readthedocs.io/en/latest/handbook/concepts.html#modes",target:"_blank",rel:"noopener noreferrer"}},[e._v("PIL 的文档"),t("OutboundLink")],1),e._v("中，我们可以看到它"),t("code",[e._v("L")]),e._v("指的是单通道灰度图像。再一次，我们可以通过将此图像转换为数组并检查形状来确认这一点。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/88f7eec5be4e925c3e7f47eeea9c164d.png",alt:""}})]),e._v(" "),t("p",[e._v("请注意，由于我们只有一个通道，因此默认情况下通道维度被完全丢弃；这可能会导致某些深度学习框架出现问题。我们可以使用 NumPy 的"),t("code",[e._v("expand_dims")]),e._v("函数显式添加通道轴。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/05c0ea1be54efc64517a7d7ef728f9d3.png",alt:""}})]),e._v(" "),t("p",[e._v("在 PyTorch 中，我们可以使用该"),t("code",[e._v("unsqueeze")]),e._v("方法完成同样的事情，如下所示：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/c9defdb0d860261dc6ad04d5daa91e3f.png",alt:""}})]),e._v(" "),t("p",[e._v("在观察了 RGB 和灰度图像之间的差异之后，我们可能会开始理解这些表示如何给模型带来问题；特别是如果模型已经在与我们目前正在训练的格式不同的图像数据集上进行了预训练。")]),e._v(" "),t("p",[e._v("目前，大多数可用的预训练模型都是在 ImageNet 数据集的一个版本上训练的，该版本包含 RGB 格式的彩色图像。因此，如果我们在灰度图像上进行微调，我们提供给预训练模型的输入与它之前遇到的任何输入都大不相同！")]),e._v(" "),t("p",[e._v("由于在撰写本文时，卷积神经网络 (CNN) 是视觉任务中最常用的预训练模型，因此我们将把重点限制在了解 CNN 如何受图像通道数量的影响；其他架构不在本文讨论范围之内！在这里，我们将假设熟悉 CNN 以及卷积的工作原理——因为有"),t("a",{attrs:{href:"https://github.com/fastai/fastbook/blob/master/13_convolutions.ipynb",target:"_blank",rel:"noopener noreferrer"}},[e._v("很好的资源"),t("OutboundLink")],1),e._v("详细介绍了这些主题——并关注这个过程将如何受到输入通道数量变化的影响。")]),e._v(" "),t("p",[e._v("出于我们的目的，要记住的关键信息是 CNN 的核心构建块是卷积层，我们可以将其视为应用一组过滤器（也称为内核）的过程——其中过滤器是只是一个小矩阵，通常是 3x3——作为图像上的滑动窗口；在对结果求和之前执行逐元素乘法。"),t("a",{attrs:{href:"https://deeplizard.com/resource/pavq7noze2",target:"_blank",rel:"noopener noreferrer"}},[e._v("可以在此处找到"),t("OutboundLink")],1),e._v("一个用于准确了解其工作原理的好工具。")]),e._v(" "),t("h2",{attrs:{id:"通道数如何影响过滤器"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#通道数如何影响过滤器"}},[e._v("#")]),e._v(" 通道数如何影响过滤器？")]),e._v(" "),t("p",[e._v("在深度学习之前的计算机视觉中，为了某些目的手动创建过滤器，例如边缘检测、模糊等。例如，让我们考虑一个用于检测水平线的手工制作的 3×3 过滤器：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/095f39342ecbd7b5b3b21c278a28da3a.png",alt:""}})]),e._v(" "),t("p",[e._v("虽然在滑动窗口操作期间在整个图像上使用相同的过滤器“权重”，但这些权重不会跨通道共享；这意味着过滤器必须始终具有与输入相同数量的通道。因此，我们想要应用于 3 通道 RGB 图像的任何过滤器也必须有 3 个通道！过滤器具有的通道数有时称为“深度”。")]),e._v(" "),t("p",[e._v("考虑到我们上面定义的水平线滤波器，为了将其应用于 3 通道图像，我们需要增加该滤波器的深度，使其为 3x3x3。由于我们希望每个通道都有相同的行为，在这种情况下，我们可以简单地在通道轴上复制 3x3 过滤器。")]),e._v(" "),t("p",[e._v("我们可以这样做，如下所示：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/7ad9fd462cd45dbfa77267ecaa685c5b.png",alt:""}})]),e._v(" "),t("p",[e._v("现在过滤器的深度与通道数兼容，我们可以将此过滤器应用于 3 通道图像！")]),e._v(" "),t("p",[e._v("为此，对于每个通道，我们将图像的滑动窗口部分的元素乘以相应过滤器的元素；这将产生一个 3x3 矩阵，该矩阵表示与每个通道的当前滤波器位置对应的特征。然后可以对这些矩阵求和以获得输出特征图的相应部分。")]),e._v(" "),t("p",[e._v("这个过程如下图所示：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/fe5235b14ee4f5299f6ef1809949f3a7.png",alt:""}})]),e._v(" "),t("p",[e._v("请注意，特征图左上角的像素对应于内核中心像素的位置。由于我们无法计算图像每个边缘上最外层像素的完整卷积，因此这些像素不会包含在特征图中。")]),e._v(" "),t("p",[e._v("我们可以重复这个过程，在图像上移动过滤器的位置，以获得完整的输出特征图。请注意，无论输入图像的通道数如何，当每个通道的特征相加时，特征图的深度始终为 1。")]),e._v(" "),t("h2",{attrs:{id:"卷积神经网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#卷积神经网络"}},[e._v("#")]),e._v(" 卷积神经网络")]),e._v(" "),t("p",[e._v("现在我们已经探索了如何将手动定义的过滤器应用于 3 通道图像，此时，您可能想知道：CNN 是从哪里来的？")]),e._v(" "),t("p",[e._v("CNN 背后的一个关键思想是，无需专家手动定义过滤器，这些过滤器可以随机初始化，我们相信优化过程可以确保这些过滤器在训练期间学会检测有意义的特征；"),t("a",{attrs:{href:"https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("此处探讨了"),t("OutboundLink")],1),e._v("CNN 学习的过滤器类型的可视化。因此，除了这些过滤器被学习而不是被定义之外，整个过程在很大程度上是相同的！")]),e._v(" "),t("p",[e._v("在 CNN 中，每个卷积层都包含与将要学习的过滤器对应的参数；初始化的随机过滤器的数量是我们可以指定的超参数。正如我们在上面的示例中看到的，每个过滤器都会创建一个单通道特征图，因此卷积层初始化的过滤器数量将决定输出通道的数量。")]),e._v(" "),t("p",[e._v("例如，假设我们有一个单通道图像，我们想创建一个学习单个 3x3 滤波器的卷积层。我们可以如下所示指定它：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/128dd5f3293dec7a58849f34807f99ce.png",alt:""}})]),e._v(" "),t("p",[e._v("在这里，我们期望过滤器的维度应该与我们之前定义的单通道水平线过滤器相同。让我们通过检查这一层的“权重”属性来确认这一点：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/f4ef79a8340654701a51d58ec98e6bd3.png",alt:""}})]),e._v(" "),t("p",[e._v("回想一下 PyTorch 默认情况下首先存储通道数，并注意到为了计算目的添加了一个批量维度，我们可以看到该层已经初始化了一个 3x3 过滤器，正如我们所期望的那样！")]),e._v(" "),t("p",[e._v("现在，让我们创建另一个卷积层，这次指定我们有 3 个输入通道——以便能够处理 RGB 图像——并检查权重。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/b614c8d2b53b59ec8a2d807ca3cd3f6c.png",alt:""}})]),e._v(" "),t("p",[e._v("与我们扩展手动定义的过滤器时类似，初始化的过滤器现在具有与输入通道数相同的深度；它给出了 3x3x3 的尺寸。")]),e._v(" "),t("p",[e._v("但是，当我们扩展手动定义的过滤器时，我们只是简单地复制了相同的权重。这里，关键区别在于每个通道的 3x3 权重会不同；使网络能够检测每个通道的不同特征。因此，每个内核都基于输入图像的每个通道学习特征，并且特定于输入图像的每个通道！")]),e._v(" "),t("p",[e._v("我们可以通过直接检查权重来确认这一点，如下所示：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/45a91596d7943aea777c32dd6ef1c1b9.png",alt:""}})]),e._v(" "),t("p",[e._v("由此，我们可以看到将应用于每个通道的 3x3 过滤器的权重不同。")]),e._v(" "),t("p",[e._v("虽然在创建新的卷积层时很容易根据我们的输入调整初始化的过滤器尺寸，但当我们开始考虑预训练架构时，这就变得更加困难。")]),e._v(" "),t("p",[e._v("例如，让我们检查"),t("a",{attrs:{href:"https://arxiv.org/pdf/2103.07579v1.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Resnet-RS50 模型"),t("OutboundLink")],1),e._v("的第一个卷积层，该模型已在"),t("a",{attrs:{href:"https://github.com/rwightman/pytorch-image-models",target:"_blank",rel:"noopener noreferrer"}},[e._v("PyTorch 图像模型 (timm) 库"),t("OutboundLink")],1),e._v("中的 ImageNet 上进行了预训练；如果您不熟悉 PyTorch 图像模型并想了解更多信息，我"),t("a",{attrs:{href:"https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055?source=friends_link&sk=3c4f742ff07279e68652bc254ed0c6e5",target:"_blank",rel:"noopener noreferrer"}},[e._v("之前已经在此处探索了该库的一些功能"),t("OutboundLink")],1),e._v("。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/6bf33256014a4e3ef52e9fecbeeae907.png",alt:""}})]),e._v(" "),t("p",[e._v("由于这个模型是在 RGB 图像上训练的，我们可以看到每个过滤器都需要一个 3 通道输入。因此，如果我们试图在单通道灰度图像上使用这个模型，这根本行不通，因为我们缺少重要信息；过滤器将尝试检测不存在的频道中的功能！")]),e._v(" "),t("p",[e._v("此外，在我们之前的示例中，我们考虑了可以学习单个过滤器的卷积层；在实践中很少出现这种情况。通常，我们希望每个卷积层都有多个过滤器，这样它们中的每一个都能够专门识别来自输入的不同特征。根据任务的不同，有些可能会学习检测水平边缘，有些可能会学习检测垂直边缘等。这些特征可以由后面的层进一步组合，使模型能够学习越来越复杂的特征表示。在这里，我们可以看到 ResNet-RS50 模型的卷积层有 32 个输出通道，这意味着它学习了 32 个不同的滤波器，每个滤波器需要 3 个通道输入！")]),e._v(" "),t("p",[e._v("现在我们了解了为什么通道数量减少的灰度图像与在 RGB 图像上训练的预训练模型不兼容，让我们探索一些可以克服这个问题的方法！")]),e._v(" "),t("p",[e._v("根据我的经验，往往有两种常用的主要方法：")]),e._v(" "),t("ul",[t("li",[e._v("为每个灰度图像添加额外的通道")]),e._v(" "),t("li",[e._v("修改预训练网络的第一个卷积层")])]),e._v(" "),t("p",[e._v("在这里，我们将探讨这两种方法。")]),e._v(" "),t("h2",{attrs:{id:"向灰度图像添加额外的通道"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#向灰度图像添加额外的通道"}},[e._v("#")]),e._v(" 向灰度图像添加额外的通道")]),e._v(" "),t("p",[e._v("可以说，将灰度图像与预训练模型一起使用的最简单方法是完全避免修改模型；相反，复制现有通道，使每个图像有 3 个通道。使用我们之前看到的相同灰度图像，让我们探索如何做到这一点。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/7e663a1137757a609cc5f4a53a63f2d4.png",alt:""}})]),e._v(" "),t("p",[t("strong",[e._v("使用 NumPy")])]),e._v(" "),t("p",[e._v("首先，我们需要将图像转换为 NumPy 数组：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/3f330e274a21f46ef54ded26007816f8.png",alt:""}})]),e._v(" "),t("p",[e._v("正如我们之前观察到的，因为我们的图像只有一个通道，所以还没有创建通道轴。再一次，我们可以使用"),t("code",[e._v("expand_dims")]),e._v("函数来添加它。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/4b229777307d8161ad9482f64ef07472.png",alt:""}})]),e._v(" "),t("p",[e._v("现在我们已经为通道维度创建了一个附加轴，我们需要做的就是在这个轴上重复我们的数据；为此，我们可以使用该"),t("code",[e._v("repeat")]),e._v("方法，如下所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/9744cd1ab98eadadd6a9af860d5394e9.png",alt:""}})]),e._v(" "),t("p",[e._v("为了方便起见，让我们将这些步骤总结成一个函数，以便我们可以在需要时轻松地重复此过程：")]),e._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("def expand\\_greyscale\\_image\\_channels(grey\\_pil\\_image):   \n grey\\_image\\_arr = np.array(grey\\_image)   \n grey\\_image\\_arr = np.expand\\_dims(grey\\_image\\_arr, -1)   \n grey\\_image\\_arr\\_3\\_channel = grey\\_image\\_arr.repeat(3, axis=-1)   \n return grey\\_image\\_arr\\_3\\_channel\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br"),t("span",{staticClass:"line-number"},[e._v("2")]),t("br"),t("span",{staticClass:"line-number"},[e._v("3")]),t("br"),t("span",{staticClass:"line-number"},[e._v("4")]),t("br"),t("span",{staticClass:"line-number"},[e._v("5")]),t("br")])]),t("p",[e._v("将此函数应用于我们的图像并绘制输出，我们可以看到生成的图像正确显示，尽管现在它有 3 个通道。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/2c24c5d34f8379a3eeaa3579504752c8.png",alt:""}})]),e._v(" "),t("p",[t("strong",[e._v("使用 PyTorch")])]),e._v(" "),t("p",[e._v("如果我们正在进行深度学习，探索如何直接使用 PyTorch 进行这种转换可能比使用 NumPy 作为中介更有用。虽然我们可以在 PyTorch 张量上执行与上述类似的一组步骤，但作为训练过程的一部分，我们可能希望对图像执行额外的转换——例如 TorchVision 中定义的数据增强操作。由于我们希望 3 通道转换发生在我们的增强管道的开始，并且一些后续转换可能需要 PIL 图像，因此直接操作张量可能不是这里的最佳方法。")]),e._v(" "),t("p",[e._v("值得庆幸的是，虽然有点违反直觉，但我们可以使用 TorchVision 中包含的现有灰度转换来为我们进行这种转换！虽然此转换需要火炬张量或 PIL 图像，因为我们希望这是我们管道中的第一步，但让我们在这里使用 PIL 图像。")]),e._v(" "),t("p",[e._v("默认情况下，此转换将 RGB 图像转换为单通道灰度图像，但我们可以使用"),t("code",[e._v("num_output_channels")]),e._v("参数修改此行为，如下所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/67fde96e5b42a0545ae46529e767978a.png",alt:""}})]),e._v(" "),t("p",[e._v("现在，让我们看看如果将此变换应用于我们的灰度图像会发生什么。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/db5696c5440e363c06b69aa6adaa6c33.png",alt:""}})]),e._v(" "),t("p",[e._v("乍一看，它看起来并没有什么变化。但是，我们可以通过检查 PIL 图像的通道和模式来确认转换是否按预期工作。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/b7e39ffb0e2e8f5ca38d43abfa41e654.png",alt:""}})]),e._v(" "),t("p",[e._v("由于添加了额外的通道，我们可以看到 PIL 现在将此图像称为 RGB 图像；这就是我们想要的！")]),e._v(" "),t("p",[e._v("因此，使用这种方法对训练脚本进行使用灰度图像所需的唯一修改是将此转换添加到增强管道中，如下所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/67b0bd7fe30b166ee60de6b3c48df40c.png",alt:""}})]),e._v(" "),t("h2",{attrs:{id:"修改预训练网络的第一个卷积层"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#修改预训练网络的第一个卷积层"}},[e._v("#")]),e._v(" 修改预训练网络的第一个卷积层")]),e._v(" "),t("p",[e._v("虽然将单通道图像扩展到 3 个通道很方便，如上所示，但这样做的潜在缺点是需要额外的资源来存储和处理额外的通道；在这种情况下不提供任何新信息！")]),e._v(" "),t("p",[e._v("一种不同的方法是修改模型以适应不同的输入，在大多数情况下，这需要修改第一个卷积层。虽然我们可以用一个新层替换整个层，但这意味着丢弃模型的一些学习权重——除非我们冻结后续层并开始单独训练新层，这需要额外的努力——输出来自这些新的、随机初始化的权重可能会对后面的一些层产生负面影响。")]),e._v(" "),t("p",[e._v("或者，回想一下卷积层中的每个过滤器都有单独的通道，我们可以沿着通道轴将它们加在一起。让我们在下面探讨如何做到这一点。我们将再次使用 PyTorch 图像模型中的 Resnet-RS50 模型。")]),e._v(" "),t("p",[e._v("首先，让我们创建预训练模型：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/fb220d42d824ec8bbaae61b8dded4518.png",alt:""}})]),e._v(" "),t("p",[e._v("正如我们所料，根据我们之前对过滤器和通道的探索，如果我们尝试在开箱即用的单通道图像上使用该模型，我们会观察到以下错误。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/41868a4eee62b2b9f7aa2f2162f91841.png",alt:""}})]),e._v(" "),t("p",[e._v("让我们通过调整第一个卷积层的权重来解决这个问题。对于这个模型，我们可以访问它，如下所示，但这将根据所使用的模型而有所不同！")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/9882858db15978d45c3c875efb0a368a.png",alt:""}})]),e._v(" "),t("p",[e._v("首先，让我们更新"),t("code",[e._v("in_channels")]),e._v("该图层的属性以反映我们的更改。这实际上并没有修改权重，但会更新打印模型时看到的概览，并确保我们能够正确保存和加载模型。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/4c12a27270c4df7e5c37f78f1a9e04cf.png",alt:""}})]),e._v(" "),t("p",[e._v("现在，让我们执行实际的权重更新。我们可以使用该"),t("code",[e._v("sum")]),e._v("方法来执行此操作，确保将"),t("code",[e._v("keepdim")]),e._v("参数设置为"),t("code",[e._v("True")]),e._v("以保留尺寸。唯一需要注意的“陷阱”是，由于"),t("code",[e._v("sum")]),e._v("操作会创建一个新的张量，我们必须将这个新张量包装在"),t("code",[e._v("nn.Parameter")]),e._v("; 这样新的权重将自动添加到模型的参数中。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/282dc22e8b86e04b38959f08400f1453.png",alt:""}})]),e._v(" "),t("p",[e._v("现在，使用带有单通道图像的模型，我们可以看到返回了正确的形状！")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/d540e837ea95912527dc68dc7d8810bd.png",alt:""}})]),e._v(" "),t("p",[t("strong",[e._v("使用时间")])]),e._v(" "),t("p",[e._v("虽然我们可以在任何 PyTorch 模型上手动执行上述步骤，但 timm 已经包含为我们执行此操作的功能！要以这种方式修改 timm 模型，我们可以"),t("code",[e._v("in_chans")]),e._v("在创建模型时使用参数，如下所示。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/12e6e420c0c4886a96b273f387d77875.png",alt:""}})]),e._v(" "),t("p",[e._v("现在我们已经研究了两种可以将灰度图像与预训练模型一起使用的方法，您可能想知道使用哪一种；或者在灰度图像上简单地从头开始训练模型是否更好！")]),e._v(" "),t("p",[e._v("然而，由于可能使用的模型、优化器、调度器和训练策略的组合几乎是无限的，以及数据集的差异，因此很难确定一个通用规则；“最佳”方法可能会因您正在调查的具体任务而异！")]),e._v(" "),t("p",[e._v("尽管如此，为了大致了解这些方法的执行情况，我决定在三个开源数据集上训练我最喜欢的模型-优化器-调度程序组合之一，以了解不同方法的比较情况。虽然改变训练策略可能会影响不同方法的执行方式，但为简单起见，训练过程保持相对一致；基于我发现行之有效的实践。")]),e._v(" "),t("h2",{attrs:{id:"实验设置"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#实验设置"}},[e._v("#")]),e._v(" 实验设置")]),e._v(" "),t("p",[e._v("对于所有实验运行，以下内容保持一致：")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("型号")]),e._v("：ResNet-RS50")]),e._v(" "),t("li",[t("strong",[e._v("优化器")]),e._v("：AdamW")]),e._v(" "),t("li",[t("strong",[e._v("LR 调度")]),e._v("器：余弦衰减")]),e._v(" "),t("li",[t("strong",[e._v("数据增强")]),e._v("：图像大小调整为 224，训练期间使用水平翻转")]),e._v(" "),t("li",[t("strong",[e._v("初始 LR")]),e._v(" : 0.001")]),e._v(" "),t("li",[t("strong",[e._v("最大纪元数")]),e._v("：60")])]),e._v(" "),t("p",[e._v("所有训练均使用单个 NVIDIA V100 GPU 进行，批量大小为 32。为了处理训练循环，我使用了"),t("a",{attrs:{href:"https://github.com/Chris-hughes10/pytorch-accelerated",target:"_blank",rel:"noopener noreferrer"}},[e._v("PyTorch 加速库"),t("OutboundLink")],1),e._v("。")]),e._v(" "),t("p",[e._v("使用的数据集是：")]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://github.com/AI-Lab-Makerere/ibean/",target:"_blank",rel:"noopener noreferrer"}},[t("strong",[e._v("Beans")]),t("OutboundLink")],1),e._v("：Beans 是使用智能手机相机在田间拍摄的豆类图像的数据集。它由3个类组成，2个疾病类和健康类。")]),e._v(" "),t("li",[t("a",{attrs:{href:"http://laurencemoroney.com/rock-paper-scissors-dataset",target:"_blank",rel:"noopener noreferrer"}},[t("strong",[e._v("剪刀石头布")]),t("OutboundLink")],1),t("strong",[e._v("(RPS)")]),e._v("：双手玩剪刀石头布游戏的图像。")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://www.robots.ox.ac.uk/~vgg/data/pets/",target:"_blank",rel:"noopener noreferrer"}},[t("strong",[e._v("Oxford Pets")]),t("OutboundLink")],1),e._v("：一个包含 37 个类别的宠物数据集，每个类别大约有 200 张图像。")])]),e._v(" "),t("p",[e._v("对于每个数据集，我探索了以下处理灰度图像的方法：")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("RGB")]),e._v("：使用 RGB 图像作为基线微调模型。")]),e._v(" "),t("li",[t("strong",[e._v("带 3 个通道")]),e._v("的灰度：灰度图像被转换为​​ 3 通道格式。")]),e._v(" "),t("li",[t("strong",[e._v("带单通道的灰度")]),e._v("：模型的第一层被转换为接受单通道图像。")])]),e._v(" "),t("p",[e._v("在与每种方法相关的地方，我使用了以下培训政策：")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("Finetune")]),e._v("：使用预训练模型，首先训练模型的最后一层，然后解冻和训练整个模型。解冻后，学习率降低了 10 倍。")]),e._v(" "),t("li",[t("strong",[e._v("Finetune whole model")]),e._v("：训练整个预训练模型，不冻结任何层。")]),e._v(" "),t("li",[t("strong",[e._v("From scratch")]),e._v(" : 从头开始​​训练模型")])]),e._v(" "),t("p",[e._v("下面提供了用于运行此实验的训练脚本，使用的软件包版本为：")]),e._v(" "),t("ul",[t("li",[e._v("火炬：1.10.0")]),e._v(" "),t("li",[e._v("PyTorch 加速：0.1.22")]),e._v(" "),t("li",[e._v("蒂姆：0.5.4")]),e._v(" "),t("li",[e._v("火炬指标：0.7.1")]),e._v(" "),t("li",[e._v("熊猫：1.4.1")])]),e._v(" "),t("h2",{attrs:{id:"结果"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#结果"}},[e._v("#")]),e._v(" 结果")]),e._v(" "),t("p",[e._v("这些运行的结果列于下表中。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://img-blog.csdnimg.cn/img_convert/aa77f854e7dcfdeca67f168b1651e0a3.png",alt:""}})]),e._v(" "),t("p",[e._v("从这些实验中，我的主要观察结果是：")]),e._v(" "),t("ul",[t("li",[e._v("使用预训练模型并将其调整为使用灰度图像，而不是从头开始训练，似乎更容易获得良好的结果。")]),e._v(" "),t("li",[e._v("这些数据集的最佳方法似乎是修改图像中的通道数，而不是修改模型。")])]),e._v(" "),t("p",[e._v("希望这对如何在灰度图像上微调预训练模型提供了一个相当全面的概述，以及对为什么需要额外考虑的理解。")]),e._v(" "),t("p",[t("em",[e._v("Chris Hughes 在")]),t("a",{attrs:{href:"http://www.linkedin.com/in/chris-hughes1/",target:"_blank",rel:"noopener noreferrer"}},[t("em",[e._v("LinkedIn")]),t("OutboundLink")],1),t("em",[e._v("上。")])]),e._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://www.image-net.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("ImageNet (image-net.org)"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://en.wikipedia.org/wiki/RGB_color_model",target:"_blank",rel:"noopener noreferrer"}},[e._v("RGB 颜色模型——维基百科"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://pillow.readthedocs.io/en/latest/handbook/concepts.html#modes",target:"_blank",rel:"noopener noreferrer"}},[e._v("概念 — Pillow (PIL Fork) 9.1.0.dev0 文档"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/fastai/fastbook/blob/master/13_convolutions.ipynb",target:"_blank",rel:"noopener noreferrer"}},[e._v("fastbook/13_convolutions.ipynb at master · fastai/fastbook (github.com)"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://deeplizard.com/resource/pavq7noze2",target:"_blank",rel:"noopener noreferrer"}},[e._v("deeplizard — 卷积演示"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("LNCS 8689 — 可视化和理解卷积网络 (nyu.edu)"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://arxiv.org/pdf/2103.07579v1.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("重温 ResNets：改进的训练和缩放策略 (arxiv.org)"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/rwightman/pytorch-image-models",target:"_blank",rel:"noopener noreferrer"}},[e._v("rwightman/pytorch-image-models：PyTorch 图像模型、脚本、预训练权重——ResNet、ResNeXT、EfficientNet、EfficientNetV2、NFNet、Vision Transformer、MixNet、MobileNet-V3/V2、RegNet、DPN、CSPNet 等（github.com） )"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055",target:"_blank",rel:"noopener noreferrer"}},[e._v("PyTorch 图像模型入门 (timm)：从业者指南 | 通过克里斯休斯 | 2022 年 2 月 | 迈向数据科学"),t("OutboundLink")],1)]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/Chris-hughes10/pytorch-accelerated",target:"_blank",rel:"noopener noreferrer"}},[e._v("Chris-hughes10/pytorch-accelerated：一个轻量级库，旨在通过提供最小但可扩展的训练循环来加速 PyTorch 模型的训练过程，该训练循环足够灵活以处理大多数用例，并且能够利用不同的硬件选项而无需需要更改代码。文档：https://pytorch-accelerated.readthedocs.io/en/latest/ (github.com)"),t("OutboundLink")],1)])]),e._v(" "),t("h2",{attrs:{id:"使用的数据集"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用的数据集"}},[e._v("#")]),e._v(" "),t("strong",[e._v("使用的数据集")])]),e._v(" "),t("ul",[t("li",[e._v("Beans 数据集，"),t("a",{attrs:{href:"https://github.com/AI-Lab-Makerere/ibean/",target:"_blank",rel:"noopener noreferrer"}},[e._v("AI-Lab-Makerere/ibean：AIR 实验室 ibean 项目的数据回购。（github.com）"),t("OutboundLink")],1),e._v("。MIT License，使用不受限制。")]),e._v(" "),t("li",[e._v("Rock, Paper, Scissors Dataset, Laurence Moroney"),t("a",{attrs:{href:"https://laurencemoroney.com/datasets.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("机器学习数据集 — Laurence Moroney — The AI Guy。"),t("OutboundLink")],1),e._v("CC By 2.0 license，免费分享和改编所有用途，商业或非商业")]),e._v(" "),t("li",[e._v("牛津宠物数据集，"),t("a",{attrs:{href:"https://www.robots.ox.ac.uk/~vgg/data/pets/",target:"_blank",rel:"noopener noreferrer"}},[e._v("视觉几何组——牛津大学"),t("OutboundLink")],1),e._v("。"),t("a",{attrs:{href:"https://creativecommons.org/licenses/by-sa/4.0/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Creative Commons Attribution-ShareAlike 4.0 International License"),t("OutboundLink")],1),e._v("，包括商业和研究目的。")])])])}),[],!1,null,null,null);t.default=_.exports}}]);