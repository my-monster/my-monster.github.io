(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{362:function(t,a,n){"use strict";n.r(a);var s=n(4),e=Object(s.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("ul",[a("li",[t._v("windows系统显示的顺序是 "),a("strong",[t._v("尺寸 = 宽 * 高")])]),t._v(" "),a("li",[t._v("opencv库中img.shape的顺序是 "),a("strong",[t._v("高 宽 通道数")])])]),t._v(" "),a("h2",{attrs:{id:"关于图像坐标系与行列宽高的关系"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#关于图像坐标系与行列宽高的关系"}},[t._v("#")]),t._v(" 关于图像坐标系与行列宽高的关系")]),t._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v(" row == height == Point.y\ncol == width  == Point.x\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br")])]),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/9bfa9ec58f7b49afa6eedc8f2cf3cd64.png",alt:"在这里插入图片描述"}}),t._v("这是因为在计算机中，图像是以矩阵的形式保存的。\n一张宽度640像素、长度480像素的灰度图保存在一个480 * 640的矩阵中。\n先行后列。\n而我们习惯的坐标表示是先X横坐标，再Y纵坐标。在OpenCV中需要对矩阵进行计算，先行再列。\n这种隐形的错误需要细心。")]),t._v(" "),a("h2",{attrs:{id:"补充-详细解释"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#补充-详细解释"}},[t._v("#")]),t._v(" 补充（详细解释）")]),t._v(" "),a("p",[t._v("坐标体系中的零点坐标为图片的左上角，X轴为图像矩形的上面那条水平线；Y轴为图像矩形左边的那条垂直线。该坐标体系在诸如结构体Mat,Rect,Point中都是适用的。（虽然网上有学着说OpenCV中有些数据结构的坐标原点是在图片的左下角，但是我暂时还没碰到过）。")]),t._v(" "),a("p",[t._v("在使用image.at(x1, x2)来访问图像中点的值的时候，x1并不是图片中对应点的x轴坐标，而是图片中对应点的y坐标。因此其访问的结果其实是访问image图像中的Point(x2, x1)点，即与image.at(Point(x2, x1))效果相同。")]),t._v(" "),a("p",[t._v("如果所画图像是多通道的，比如说image图像的通道数时n，则使用Mat::at(x, y)时，其x的范围依旧是0到image的height，而y的取值范围则是0到image的width乘以n，因为这个时候是有n个通道，所以每个像素需要占有n列。但是如果在同样的情况下，使用Mat::at(point)来访问的话，则这时候可以不用考虑通道的个数，因为你要赋值给获取Mat::at(point)的值时，都不是一个数字，而是一个对应的n维向量。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/8c161de91911499a87e1757d9a995c5f.png",alt:"在这里插入图片描述"}})])])}),[],!1,null,null,null);a.default=e.exports}}]);