<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>torch.optim.lr_scheduler.MultiStepLR()用法研究 台阶_阶梯学习率 | Liuyuan&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="个人博客。">
    <meta name="keywords" content="个人博客。">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.6b291d34.css" as="style"><link rel="preload" href="/assets/js/app.50fadf31.js" as="script"><link rel="preload" href="/assets/js/2.47a03fa1.js" as="script"><link rel="preload" href="/assets/js/3.436c0527.js" as="script"><link rel="preload" href="/assets/js/13.00db5453.js" as="script"><link rel="prefetch" href="/assets/js/10.a34e71ca.js"><link rel="prefetch" href="/assets/js/11.97b02391.js"><link rel="prefetch" href="/assets/js/12.8e6e4c4b.js"><link rel="prefetch" href="/assets/js/14.e91dd435.js"><link rel="prefetch" href="/assets/js/15.6018daa8.js"><link rel="prefetch" href="/assets/js/16.d7372590.js"><link rel="prefetch" href="/assets/js/17.d89a4381.js"><link rel="prefetch" href="/assets/js/18.ea92a9c3.js"><link rel="prefetch" href="/assets/js/19.825ba7c0.js"><link rel="prefetch" href="/assets/js/20.8330b139.js"><link rel="prefetch" href="/assets/js/21.e65d87fa.js"><link rel="prefetch" href="/assets/js/22.84ef7201.js"><link rel="prefetch" href="/assets/js/23.c4c00f09.js"><link rel="prefetch" href="/assets/js/24.1474c794.js"><link rel="prefetch" href="/assets/js/25.607370fa.js"><link rel="prefetch" href="/assets/js/26.85790132.js"><link rel="prefetch" href="/assets/js/27.251cd882.js"><link rel="prefetch" href="/assets/js/28.87d9bae7.js"><link rel="prefetch" href="/assets/js/29.59230516.js"><link rel="prefetch" href="/assets/js/30.515bed4d.js"><link rel="prefetch" href="/assets/js/31.6eac8e06.js"><link rel="prefetch" href="/assets/js/32.e79b26fb.js"><link rel="prefetch" href="/assets/js/33.eee2be0d.js"><link rel="prefetch" href="/assets/js/34.22836300.js"><link rel="prefetch" href="/assets/js/35.1bb64409.js"><link rel="prefetch" href="/assets/js/36.7fb27be9.js"><link rel="prefetch" href="/assets/js/37.54e1ee25.js"><link rel="prefetch" href="/assets/js/38.e1fd2084.js"><link rel="prefetch" href="/assets/js/39.aa56611a.js"><link rel="prefetch" href="/assets/js/4.54ba375b.js"><link rel="prefetch" href="/assets/js/40.ae81606b.js"><link rel="prefetch" href="/assets/js/41.0b9b9a66.js"><link rel="prefetch" href="/assets/js/42.1ac387fb.js"><link rel="prefetch" href="/assets/js/43.5ce9c58b.js"><link rel="prefetch" href="/assets/js/44.750f46f0.js"><link rel="prefetch" href="/assets/js/45.d92dc275.js"><link rel="prefetch" href="/assets/js/46.22138ea3.js"><link rel="prefetch" href="/assets/js/47.c5cd0fb4.js"><link rel="prefetch" href="/assets/js/48.a6b8db9f.js"><link rel="prefetch" href="/assets/js/49.5be7f37d.js"><link rel="prefetch" href="/assets/js/5.7e641334.js"><link rel="prefetch" href="/assets/js/50.3bbc1ed4.js"><link rel="prefetch" href="/assets/js/51.69439a8b.js"><link rel="prefetch" href="/assets/js/52.6765e0d8.js"><link rel="prefetch" href="/assets/js/53.b7f818bd.js"><link rel="prefetch" href="/assets/js/54.fa6416de.js"><link rel="prefetch" href="/assets/js/55.14d3b063.js"><link rel="prefetch" href="/assets/js/56.8db2a655.js"><link rel="prefetch" href="/assets/js/57.2c520b79.js"><link rel="prefetch" href="/assets/js/58.926c69a8.js"><link rel="prefetch" href="/assets/js/59.303cfc72.js"><link rel="prefetch" href="/assets/js/6.40ea68d2.js"><link rel="prefetch" href="/assets/js/7.86d54bc0.js"><link rel="prefetch" href="/assets/js/8.fe46a857.js"><link rel="prefetch" href="/assets/js/9.dc879685.js">
    <link rel="stylesheet" href="/assets/css/0.styles.6b291d34.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Liuyuan's blog" class="logo"> <span class="site-name can-hide">Liuyuan's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/blog/" class="nav-link">blog搬运</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/my-monster/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/myself.jpg"> <div class="blogger-info"><h3>Liu Yuan</h3> <span>热爱生活！</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/blog/" class="nav-link">blog搬运</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/my-monster/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>降噪</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>pytorch学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/650608/" class="sidebar-link">训练时的学习率调整：optimizer和scheduler - 知乎</a></li><li><a href="/pages/6d6261/" aria-current="page" class="active sidebar-link">torch.optim.lr_scheduler.MultiStepLR()用法研究 台阶_阶梯学习率</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/6d6261/#一、结论" class="sidebar-link">一、结论：</a></li><li class="sidebar-sub-header level2"><a href="/pages/6d6261/#二、实验代码如下" class="sidebar-link">二、实验代码如下：</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#_1、首先是默认配置" class="sidebar-link">1、首先是默认配置：</a></li><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#_2、设置last-epoch-1。" class="sidebar-link">2、设置last_epoch=-1。</a></li><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#_3、设置last-epoch-4。" class="sidebar-link">3、设置last_epoch=4。</a></li><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#_4、设置last-epoch-4-并且将scheduler-step-改为schduler-step-epoch-。也是不对" class="sidebar-link">4、设置last_epoch=4，并且将scheduler.step()改为schduler.step(epoch)。也是不对</a></li><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#我试过了-无论把last-epoch改为多少-输出都是上面这个。证明scheduler-step-里面是一定不能加epoch的" class="sidebar-link">我试过了，无论把last_epoch改为多少，输出都是上面这个。证明scheduler.step()里面是一定不能加epoch的</a></li><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#_5、接3-当last-epoch大于milestones的某些值时-会自动跳过这些值" class="sidebar-link">5、接3，当last_epoch大于milestones的某些值时，会自动跳过这些值</a></li><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#对比第3小节和第5小节的例子可以发现-在3中的例子中-4大于3-所以把3跳过了-直接在milestone-6的时候调整的learning-rate" class="sidebar-link">对比第3小节和第5小节的例子可以发现，在3中的例子中，4大于3，所以把3跳过了，直接在milestone=6的时候调整的learning_rate</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/6d6261/#三、新版本pytorch没有get-lr-这个函数了-用get-last-lr-代替" class="sidebar-link">三、新版本pytorch没有get_lr()这个函数了，用get_last_lr()代替</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#_1、官方文档" class="sidebar-link">1、官方文档：</a></li><li class="sidebar-sub-header level3"><a href="/pages/6d6261/#_2、例子代码" class="sidebar-link">2、例子代码：</a></li></ul></li></ul></li><li><a href="/pages/9b5eec/" class="sidebar-link">torch.nn.Flatten()的参数实例</a></li><li><a href="/pages/bb0c5d/" class="sidebar-link">torch.matmul()函数用法总结</a></li><li><a href="/pages/c099f4/" class="sidebar-link">【转载】PyTorch 图像模型入门 (timm)：从业者指南</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>预训练模型处理</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>学习笔记</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-5add8e0a><div class="articleInfo" data-v-5add8e0a><ul class="breadcrumbs" data-v-5add8e0a><li data-v-5add8e0a><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-5add8e0a></a></li> <li data-v-5add8e0a><a href="/research/#学术搬砖" data-v-5add8e0a>学术搬砖</a></li><li data-v-5add8e0a><a href="/research/#pytorch学习" data-v-5add8e0a>pytorch学习</a></li></ul> <div class="info" data-v-5add8e0a><div title="作者" class="author iconfont icon-touxiang" data-v-5add8e0a><a href="https://github.com/my-monster" target="_blank" title="作者" class="beLink" data-v-5add8e0a>liuyuan</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-5add8e0a><a href="javascript:;" data-v-5add8e0a>2023-03-13</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">torch.optim.lrscheduler.MultiStepLR()用法研究 台阶阶梯学习率<!----></h1>  <div class="theme-vdoing-content content__default"><h3 id="torch-optim-lr-scheduler-multisteplr-optimizer-milestones-gamma-0-1-last-epoch-1-verbose-false"><a href="#torch-optim-lr-scheduler-multisteplr-optimizer-milestones-gamma-0-1-last-epoch-1-verbose-false" class="header-anchor">#</a> <code>torch.optim.lr_scheduler.MultiStepLR</code>(<em>optimizer</em>, <em>milestones</em>, <em>gamma=0.1</em>, <em>last_epoch=-1</em>, <em>verbose=False</em>)</h3> <h2 id="一、结论"><a href="#一、结论" class="header-anchor">#</a> 一、结论：</h2> <ol><li><strong>last_epoch的用法</strong>：last_epoch表示已经走了多少个epoch，下一个milestone减去last_epoch就是需要的epoch数<br>
（评论区原话：last_epoch是有用的，简单来说，就是所有学习率都要提前last_epoch开始进行变化。举个例子假如我设置原始lr=0.1，milestones=[5, 15], gamma=0.5，last_epoch=0此时epoch=5时lr才会变为0.05，epoch=15时lr变为0.025。当修改last_epoch=3后，epoch=2，lr就会变为0.05，epoch=12，lr变为0.025.一般默认last_epoch=0）</li> <li><strong>使用scheduler.get_lr()，会在milestone的时候乘以gamma的平方</strong></li> <li><strong>新版本pytorch已经有了新的变化：</strong><br>
新版的pytorch没有get_lr()函数了，应该用get_last_lr()代替get_lr()，而且 get_last_lr() 也没有 &quot;乘gamma平方&quot; 这个问题了</li></ol> <h2 id="二、实验代码如下"><a href="#二、实验代码如下" class="header-anchor">#</a> 二、实验代码如下：</h2> <h3 id="_1、首先是默认配置"><a href="#_1、首先是默认配置" class="header-anchor">#</a> 1、首先是默认配置：</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>import torch
import torchvision
 
learing_rate = 0.1
model = torchvision.models.resnet18()
optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate,
                                momentum=0.9,
                                weight_decay=5e-5)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 6], gamma=0.1)
 
for epoch in range(9):
    optimizer.step()
    scheduler.step()
    # print(optimizer.get_lr())
    print(epoch, scheduler.get_lr())
 
返回：
0 [0.1]
1 [0.1]
2 [0.0010000000000000002]   # 此处乘的是gamma的平方
3 [0.010000000000000002]
4 [0.010000000000000002]
5 [0.00010000000000000003]   # 此处乘的是gamma的平方
6 [0.0010000000000000002]
7 [0.0010000000000000002]
8 [0.0010000000000000002]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br></div></div><h3 id="_2、设置last-epoch-1。"><a href="#_2、设置last-epoch-1。" class="header-anchor">#</a> 2、设置last_epoch=-1。</h3> <p>和前面1、是一样的，因为函数的默认值就是last_epoch=-1</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import torch
import torchvision
 
learing_rate = 0.1
model = torchvision.models.resnet18()
optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate,
                                momentum=0.9,
                                weight_decay=5e-5)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 6], gamma=0.1)
scheduler.last_epoch = -1
 
for epoch in range(9):
    optimizer.step()
    scheduler.step()
    # print(optimizer.get_lr())
    print(epoch, scheduler.get_lr())
 
返回：
0 [0.1]
1 [0.1]
2 [0.1]
3 [0.0010000000000000002]
4 [0.010000000000000002]
5 [0.010000000000000002]
6 [0.00010000000000000003]
7 [0.0010000000000000002]
8 [0.0010000000000000002]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><h3 id="_3、设置last-epoch-4。"><a href="#_3、设置last-epoch-4。" class="header-anchor">#</a> 3、设置last_epoch=4。</h3> <p>把第1个epoch的learning_rate设置为0.1，但是按照模型已经更新到了第4个epoch开始执行。</p> <p>后来理解了一下，感觉就是：在last_epoch处将learning_rate重新设置为初始值，而且也是从last_epoch处继续进行运行；所以就<strong>要求你手动把learning_rate设为上一次模型停止的时候对应的learning_rate值，即last_epoch处对应的learning_rate</strong>。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import torch
import torchvision
 
learing_rate = 0.1
model = torchvision.models.resnet18()
optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate,
                                momentum=0.9,
                                weight_decay=5e-5)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 6], gamma=0.1)
scheduler.last_epoch = 4
 
for epoch in range(9):
    optimizer.step()
    scheduler.step()
    # print(optimizer.get_lr())
    print(epoch, scheduler.get_lr())
 
返回：
0 [0.1] # 0相当于第4个eopch
1 [0.0010000000000000002]  # 1相当于第5个epoch所以乘以gamma的平方
2 [0.010000000000000002]
3 [0.010000000000000002]
4 [0.010000000000000002]
5 [0.010000000000000002]
6 [0.010000000000000002]
7 [0.010000000000000002]
8 [0.010000000000000002]  # 因为4在3的后面，只有一个6这个milestones，所以只更新了一次
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><h3 id="_4、设置last-epoch-4-并且将scheduler-step-改为schduler-step-epoch-。也是不对"><a href="#_4、设置last-epoch-4-并且将scheduler-step-改为schduler-step-epoch-。也是不对" class="header-anchor">#</a> 4、设置last_epoch=4，并且将scheduler.step()改为schduler.step(epoch)。也是不对</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>import torch
import torchvision
 
learing_rate = 0.1
model = torchvision.models.resnet18()
optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate,
                                momentum=0.9,
                                weight_decay=5e-5)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 6], gamma=0.1)
scheduler.last_epoch = 4
 
for epoch in range(9):
    optimizer.step()
    scheduler.step(epoch)
    # print(optimizer.get_lr())
    print(epoch, scheduler.get_lr())
 
返回：
0 [0.0010000000000000002]
1 [0.0010000000000000002]
2 [0.0010000000000000002]
3 [0.00010000000000000003]
4 [0.0010000000000000002]
5 [0.0010000000000000002]
6 [0.00010000000000000003]
7 [0.0010000000000000002]
8 [0.0010000000000000002]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><h3 id="我试过了-无论把last-epoch改为多少-输出都是上面这个。证明scheduler-step-里面是一定不能加epoch的"><a href="#我试过了-无论把last-epoch改为多少-输出都是上面这个。证明scheduler-step-里面是一定不能加epoch的" class="header-anchor">#</a> 我试过了，无论把last_epoch改为多少，输出都是上面这个。证明scheduler.step()里面是一定不能加epoch的</h3> <h3 id="_5、接3-当last-epoch大于milestones的某些值时-会自动跳过这些值"><a href="#_5、接3-当last-epoch大于milestones的某些值时-会自动跳过这些值" class="header-anchor">#</a> <strong>5、接3，当last_epoch大于milestones的某些值时，会自动跳过这些值</strong></h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>import torch
import torchvision
 
learing_rate = 0.1
model = torchvision.models.resnet18()
optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate,
                                momentum=0.9,
                                weight_decay=5e-5)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 8], gamma=0.1)
scheduler.last_epoch = 4
 
for epoch in range(9):
    optimizer.step()
    # scheduler.step(epoch)
    scheduler.step()
    # print(optimizer.get_lr())
    print(epoch, scheduler.get_lr())
 
返回：
0 [0.0010000000000000002]
1 [0.010000000000000002]
2 [0.010000000000000002]
3 [0.00010000000000000003]
4 [0.0010000000000000002]
5 [0.0010000000000000002]
6 [0.0010000000000000002]
7 [0.0010000000000000002]
8 [0.0010000000000000002]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h3 id="对比第3小节和第5小节的例子可以发现-在3中的例子中-4大于3-所以把3跳过了-直接在milestone-6的时候调整的learning-rate"><a href="#对比第3小节和第5小节的例子可以发现-在3中的例子中-4大于3-所以把3跳过了-直接在milestone-6的时候调整的learning-rate" class="header-anchor">#</a> 对比第3小节和第5小节的例子可以发现，在3中的例子中，4大于3，所以把3跳过了，直接在milestone=6的时候调整的learning_rate</h3> <h2 id="三、新版本pytorch没有get-lr-这个函数了-用get-last-lr-代替"><a href="#三、新版本pytorch没有get-lr-这个函数了-用get-last-lr-代替" class="header-anchor">#</a> 三、新版本pytorch没有get_lr()这个函数了，用get_last_lr()代替</h2> <h3 id="_1、官方文档"><a href="#_1、官方文档" class="header-anchor">#</a> 1、官方文档：</h3> <blockquote><p><strong><code>get_last_lr</code>()：</strong></p> <p>Return the last computed learning rate by current <a href="https://so.csdn.net/so/search?q=scheduler&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener noreferrer">scheduler<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.（获取scheduler计算的最后学习速率）</p> <p><strong><code>print_lr</code>(<em>is_verbose</em>, <em>group</em>, <em>lr</em>, <em>epoch=None</em>)：# 这个怎么用，还没空研究</strong></p> <p>Display the current learning rate.（返回当前的学习率）</p> <p><strong>看来，现在没有get_lr()这个函数了</strong></p></blockquote> <h3 id="_2、例子代码"><a href="#_2、例子代码" class="header-anchor">#</a> 2、例子代码：</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>import torch
import torchvision
 
learing_rate = 0.1
model = torchvision.models.resnet18()
optimizer = torch.optim.SGD(model.parameters(), lr=learing_rate,
                                momentum=0.9,
                                weight_decay=5e-5)
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 6], gamma=0.1)
 
for epoch in range(9):
    optimizer.step()
    scheduler.step()
    # print(optimizer.get_lr())
    print(epoch, scheduler.get_last_lr())
 
 
 
返回：
0 [0.1]
1 [0.1]
2 [0.010000000000000002]
3 [0.010000000000000002]
4 [0.010000000000000002]
5 [0.0010000000000000002]
6 [0.0010000000000000002]
7 [0.0010000000000000002]
8 [0.0010000000000000002]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><p>可以看到：没有“乘以gamma平方”这个问题了。</p> <p>ps: 是评论区的 angleboy8 朋友发现的。</p></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/my-monster/blog/edit/master/docs/01.学术搬砖/02.pytorch学习/02.torch.optim.lr_scheduler.MultiStepLR()用法研究 台阶_阶梯学习率.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/03/13, 14:43:19</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/650608/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">训练时的学习率调整：optimizer和scheduler - 知乎</div></a> <a href="/pages/9b5eec/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">torch.nn.Flatten()的参数实例</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/650608/" class="prev">训练时的学习率调整：optimizer和scheduler - 知乎</a></span> <span class="next"><a href="/pages/9b5eec/">torch.nn.Flatten()的参数实例</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/e0fcae/"><div>
            为什么深度学习去噪都采用高斯白噪声？
            <!----></div></a> <span class="date">03-13</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/cf75c3/"><div>
            深度学习在图像去噪方面最近有哪些进展，与传统方法相比效果如何？
            <!----></div></a> <span class="date">03-13</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/650608/"><div>
            训练时的学习率调整：optimizer和scheduler - 知乎
            <!----></div></a> <span class="date">03-13</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1335844747@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/my-monster" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=463807063" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2023
    <span>Evan Xu | <a href="https://github.com/my-monster" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.50fadf31.js" defer></script><script src="/assets/js/2.47a03fa1.js" defer></script><script src="/assets/js/3.436c0527.js" defer></script><script src="/assets/js/13.00db5453.js" defer></script>
  </body>
</html>
