<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>深度学习在图像去噪方面最近有哪些进展，与传统方法相比效果如何？ | Liuyuan&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="个人博客。">
    <meta name="keywords" content="个人博客。">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.6b291d34.css" as="style"><link rel="preload" href="/assets/js/app.50fadf31.js" as="script"><link rel="preload" href="/assets/js/2.47a03fa1.js" as="script"><link rel="preload" href="/assets/js/3.436c0527.js" as="script"><link rel="preload" href="/assets/js/11.97b02391.js" as="script"><link rel="prefetch" href="/assets/js/10.a34e71ca.js"><link rel="prefetch" href="/assets/js/12.8e6e4c4b.js"><link rel="prefetch" href="/assets/js/13.00db5453.js"><link rel="prefetch" href="/assets/js/14.e91dd435.js"><link rel="prefetch" href="/assets/js/15.6018daa8.js"><link rel="prefetch" href="/assets/js/16.d7372590.js"><link rel="prefetch" href="/assets/js/17.d89a4381.js"><link rel="prefetch" href="/assets/js/18.ea92a9c3.js"><link rel="prefetch" href="/assets/js/19.825ba7c0.js"><link rel="prefetch" href="/assets/js/20.8330b139.js"><link rel="prefetch" href="/assets/js/21.e65d87fa.js"><link rel="prefetch" href="/assets/js/22.84ef7201.js"><link rel="prefetch" href="/assets/js/23.c4c00f09.js"><link rel="prefetch" href="/assets/js/24.1474c794.js"><link rel="prefetch" href="/assets/js/25.607370fa.js"><link rel="prefetch" href="/assets/js/26.85790132.js"><link rel="prefetch" href="/assets/js/27.251cd882.js"><link rel="prefetch" href="/assets/js/28.87d9bae7.js"><link rel="prefetch" href="/assets/js/29.59230516.js"><link rel="prefetch" href="/assets/js/30.515bed4d.js"><link rel="prefetch" href="/assets/js/31.6eac8e06.js"><link rel="prefetch" href="/assets/js/32.e79b26fb.js"><link rel="prefetch" href="/assets/js/33.eee2be0d.js"><link rel="prefetch" href="/assets/js/34.22836300.js"><link rel="prefetch" href="/assets/js/35.1bb64409.js"><link rel="prefetch" href="/assets/js/36.7fb27be9.js"><link rel="prefetch" href="/assets/js/37.54e1ee25.js"><link rel="prefetch" href="/assets/js/38.e1fd2084.js"><link rel="prefetch" href="/assets/js/39.aa56611a.js"><link rel="prefetch" href="/assets/js/4.54ba375b.js"><link rel="prefetch" href="/assets/js/40.ae81606b.js"><link rel="prefetch" href="/assets/js/41.0b9b9a66.js"><link rel="prefetch" href="/assets/js/42.1ac387fb.js"><link rel="prefetch" href="/assets/js/43.5ce9c58b.js"><link rel="prefetch" href="/assets/js/44.750f46f0.js"><link rel="prefetch" href="/assets/js/45.d92dc275.js"><link rel="prefetch" href="/assets/js/46.22138ea3.js"><link rel="prefetch" href="/assets/js/47.c5cd0fb4.js"><link rel="prefetch" href="/assets/js/48.a6b8db9f.js"><link rel="prefetch" href="/assets/js/49.5be7f37d.js"><link rel="prefetch" href="/assets/js/5.7e641334.js"><link rel="prefetch" href="/assets/js/50.3bbc1ed4.js"><link rel="prefetch" href="/assets/js/51.69439a8b.js"><link rel="prefetch" href="/assets/js/52.6765e0d8.js"><link rel="prefetch" href="/assets/js/53.b7f818bd.js"><link rel="prefetch" href="/assets/js/54.fa6416de.js"><link rel="prefetch" href="/assets/js/55.14d3b063.js"><link rel="prefetch" href="/assets/js/56.8db2a655.js"><link rel="prefetch" href="/assets/js/57.2c520b79.js"><link rel="prefetch" href="/assets/js/58.926c69a8.js"><link rel="prefetch" href="/assets/js/59.303cfc72.js"><link rel="prefetch" href="/assets/js/6.40ea68d2.js"><link rel="prefetch" href="/assets/js/7.86d54bc0.js"><link rel="prefetch" href="/assets/js/8.fe46a857.js"><link rel="prefetch" href="/assets/js/9.dc879685.js">
    <link rel="stylesheet" href="/assets/css/0.styles.6b291d34.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Liuyuan's blog" class="logo"> <span class="site-name can-hide">Liuyuan's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/blog/" class="nav-link">blog搬运</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/my-monster/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/myself.jpg"> <div class="blogger-info"><h3>Liu Yuan</h3> <span>热爱生活！</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/blog/" class="nav-link">blog搬运</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/my-monster/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>降噪</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/e0fcae/" class="sidebar-link">为什么深度学习去噪都采用高斯白噪声？</a></li><li><a href="/pages/cf75c3/" aria-current="page" class="active sidebar-link">深度学习在图像去噪方面最近有哪些进展，与传统方法相比效果如何？</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>pytorch学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>预训练模型处理</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>学习笔记</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-5add8e0a><div class="articleInfo" data-v-5add8e0a><ul class="breadcrumbs" data-v-5add8e0a><li data-v-5add8e0a><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-5add8e0a></a></li> <li data-v-5add8e0a><a href="/research/#学术搬砖" data-v-5add8e0a>学术搬砖</a></li><li data-v-5add8e0a><a href="/research/#降噪" data-v-5add8e0a>降噪</a></li></ul> <div class="info" data-v-5add8e0a><div title="作者" class="author iconfont icon-touxiang" data-v-5add8e0a><a href="https://github.com/my-monster" target="_blank" title="作者" class="beLink" data-v-5add8e0a>liuyuan</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-5add8e0a><a href="javascript:;" data-v-5add8e0a>2023-03-13</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><!----> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">深度学习在图像去噪方面最近有哪些进展，与传统方法相比效果如何？<!----></h1>  <div class="theme-vdoing-content content__default"><p>深度学习依赖于数据，而<strong>在仿真图像去噪上，数据（也就是干净图像）是非常充足的。</strong></p> <p><strong>与传统方法相比，深度学习可以在固定模式的图像去噪（比如<a href="https://www.zhihu.com/search?q=%E9%AB%98%E6%96%AF%E7%99%BD%E5%99%AA%E5%A3%B0&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A241658817%7D" target="_blank" rel="noopener noreferrer">高斯白噪声<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）问题上取得更高的PSNR和SSIM，图像质量上也会有一定的提升。</strong></p> <p>用深度学习做图像去噪不是一下子就这么成功的，这是一个缓慢不断上升的过程。我给出基于我的认识的一个TimeTable，如下：</p> <p>09年，有一篇文章<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/3506-natural-image-denoising-with-convolutional-networks" target="_blank" rel="noopener noreferrer">Natural image denoising with convolutional networks，NIPS, 2009.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 效果一般。只是比BLS-GSM, FoE的PSNR稍微好一点。</p> <p>在2012年，出现了两个用深度学习做去噪的工作。一篇是<a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/4686-image-denoising-and-inpainting-with-deep-neural-networks" target="_blank" rel="noopener noreferrer">Image Denoising and Inpainting with Deep Neural Networks, NIPS, 2012.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 另一篇是<a href="https://link.zhihu.com/?target=http%3A//ieeexplore.ieee.org/abstract/document/6247952/" target="_blank" rel="noopener noreferrer">Image denoising: Can plain neural networks compete with BM3D?， CVPR, 2012.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 后一篇比较出名一些，一般称为MLP模型。</p> <p>这时候的网络都不是很深，只有3层左右。效果也就是和BM3D差不多的水平。</p> <p>在2014-2015年，出现了一些判别学习的方法出现，比如CSF和TNRD，这两个方法虽然不是明确的深度学习方法，但也是学习几层<a href="https://www.zhihu.com/search?q=filter&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A241658817%7D" target="_blank" rel="noopener noreferrer">filter<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>去去噪，可以放在深度学习的框架内。</p> <p>CSF：<a href="https://link.zhihu.com/?target=https%3A//www.cv-foundation.org/openaccess/content_cvpr_2014/html/Schmidt_Shrinkage_Fields_for_2014_CVPR_paper.html" target="_blank" rel="noopener noreferrer">Shrinkage Fields for Effective Image Restoration. CVPR，2014.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>TNRD：<a href="https://link.zhihu.com/?target=https%3A//www.cv-foundation.org/openaccess/content_cvpr_2015/html/Chen_On_Learning_Optimized_2015_CVPR_paper.html" target="_blank" rel="noopener noreferrer">On Learning Optimized Reaction Diffusion Processes for Effective Image Restoration. CVPR, 2015.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>这些方法的PSNR/SSIM基本超过了BM3D，在速度上也不分伯仲。</p> <p>2016年，Chunhua Shen老师组有一个工作发表在NIPS上，我觉得效果是非常不错的。</p> <p><a href="https://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/6172-image-restoration-using-very-deep-convolutional-encoder-decoder-networks-with-symmetric-skip-connections" target="_blank" rel="noopener noreferrer">Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections，NIPS, 2016.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>2017年，左老师组张凯的工作：<a href="https://link.zhihu.com/?target=http%3A//ieeexplore.ieee.org/document/7839189/" target="_blank" rel="noopener noreferrer">Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising. IEEE Transactions on Image Processing,2017<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。ResNet+BN简单有效。</p> <p>不过我个人觉得，从研究的角度讲，我不主张纯刷“去高斯白噪声”这个问题的performance，这也是Michael Elad的观点。他很出名的一句话是“who cares PSNR?!”。因为高斯白噪声在现实的相机里是基本不存在的，只是作为拟合的噪声用来测试模型的效果。如果要刷performance，更应该去做真实噪声的去噪问题，这样还算做实际应用。</p> <p>虽然图像去噪这个问题很小，但是还是有研究的意义的。因为<a href="https://www.zhihu.com/search?q=%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A241658817%7D" target="_blank" rel="noopener noreferrer">图像去噪<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>是所有图像修复模型的基础，如果一个模型想在图像修复领域里得到认可，那么这个模型首先要在图像去噪这个问题上试一把。</p> <p>我鼓励大家把高斯白噪声作为一个研究的问题，理解这个问题有助于提出新的图像修复的模型。同时我鼓励大家去刷真实去噪这个问题的performance，这才是真正有使用价值的算法。</p> <p><strong>在真实图像去噪上，数据（也就是真实噪声图像和相应的干净图像）是非常不充足甚至是极度匮乏的。</strong> 在真实噪声去噪上，目前也有用深度学习的算法，比如：</p> <p><a href="https://link.zhihu.com/?target=http%3A//ieeexplore.ieee.org/document/7780555/" target="_blank" rel="noopener noreferrer">A Holistic Approach to Cross-Channel Image Noise Modeling and Its Application to Image Denoising, CVPR, 2016.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>这个方法就是用之前提到的MLP训练得到真实噪声图里的噪声分布情况，然后用<a href="https://link.zhihu.com/?target=https%3A//link.springer.com/chapter/10.1007%252F978-3-540-72823-8_45%3FLI%3Dtrue" target="_blank" rel="noopener noreferrer">Bayesian Nonlocal Means Filter<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>算法做去噪的。</p> <p>后来我本人开始考虑真实噪声图里R, G, B三个通道理的噪声分布不一样的情形，并基于传统的低秩模型提出了一个新的模型：</p> <p><a href="https://link.zhihu.com/?target=http%3A//openaccess.thecvf.com/content_iccv_2017/html/Xu_Multi-Channel_Weighted_Nuclear_ICCV_2017_paper.html" target="_blank" rel="noopener noreferrer">Multi-channel Weighted Nuclear Norm Minimization for Real Color Image Denoising. ICCV, 2017.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>2018年出现的工作：</p> <ol><li>左老师组果实的工作：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1807.04686" target="_blank" rel="noopener noreferrer">Toward Convolutional Blind Denoising of Real Photographs<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</li> <li>Roth老师组发表在NeurIPS2018的工作：<a href="https://link.zhihu.com/?target=https%3A//github.com/visinf/n3net" target="_blank" rel="noopener noreferrer">Neural Nearest Neighbors Networks<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1811.11127" target="_blank" rel="noopener noreferrer">Unprocessing Images for Learned Raw Denoising<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ol> <p><strong>目前真实去噪的一大难点就在于如何得到Ground Truth。</strong></p> <p>目前一般采取多次拍摄固定场景再取平均的方法，比如<a href="https://link.zhihu.com/?target=http%3A//ieeexplore.ieee.org/document/7780555/" target="_blank" rel="noopener noreferrer">A Holistic Approach to Cross-Channel Image Noise Modeling and Its Application to Image Denoising, CVPR, 2016.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>文章里就用这个方法做了一个小的数据库，里面一共有15张512x512的图。</p> <p>我们也用这样的方法采集了一个更大的数据库，叫<a href="https://link.zhihu.com/?target=https%3A//github.com/csjunxu/PolyU-Real-World-Noisy-Images-Dataset" target="_blank" rel="noopener noreferrer">PolyU Dataset<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。具体过程见以下文章：</p> <p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1804.02603" target="_blank" rel="noopener noreferrer">Real-world Noisy Image Denoising: A New Benchmark<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><strong>.</strong></p> <p>另外的办法就是拍摄一张低ISO的图片和一张高ISO的图片，然后通过一系列后续处理使得这两张图看起来像是在同样的条件下拍摄得到的。德国的Roth组就用这个想法建立了一个大的数据库，一共有50张图，每张图截出20张512x512的小图，一共1000张。文章：<a href="https://link.zhihu.com/?target=http%3A//openaccess.thecvf.com/content_cvpr_2017/papers/Plotz_Benchmarking_Denoising_Algorithms_CVPR_2017_paper.pdf" target="_blank" rel="noopener noreferrer">Benchmarking Denoising Algorithms with Real Photographs. CVPR, 2017.<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><strong>另一大难点是真实图像里的噪声是信号相关的，没有一个明确的分布可以模拟。</strong></p> <p>目前在模拟真实噪声分布这个问题上，我们最近提出了对不同的图像通道，和不同的图像块都采取不同方差的<a href="https://www.zhihu.com/search?q=%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A241658817%7D" target="_blank" rel="noopener noreferrer">高斯分布<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>去拟合真实噪声。这个是基于我们的观察，如下图：</p> <p><img src="https://pic4.zhimg.com/80/v2-d8eebfcc4549215939ca073a41c835c0_720w.webp?source=1940ef5c" alt=""></p> <p>真实噪声图</p> <p><img src="https://pic3.zhimg.com/80/v2-0010f9970713037982224562ae87fb86_720w.webp?source=1940ef5c" alt=""></p> <p>噪声图减去均值图，得到真实噪声分布</p> <p><img src="https://pic3.zhimg.com/80/v2-41cced8ef273086b6f9ec5874d7402a3_720w.webp?source=1940ef5c" alt=""></p> <p>全局的噪声的分布直方图</p> <p><img src="https://pic1.zhimg.com/80/v2-08d817968abd29719585f527c8478499_720w.webp?source=1940ef5c" alt=""></p> <p>噪声分布图中白色框内的噪声分布直方图，红色通道</p> <p><img src="https://pic2.zhimg.com/80/v2-893788eab1148ec4e8fbd16c78b353de_720w.webp?source=1940ef5c" alt=""></p> <p>噪声分布图中白色框内的噪声分布直方图，绿色通道</p> <p><img src="https://pic1.zhimg.com/80/v2-a4c300e3511f29d21d2a348a460c2b33_720w.webp?source=1940ef5c" alt=""></p> <p>噪声分布图中白色框内的噪声分布直方图，蓝色通道</p> <p>根据上面例子的观察，我们可以得出结论：真实噪声图的全局噪声不是高斯分布，但所有局部图像块的不同通道的噪声可以近似看作是方差不同的高斯分布。</p> <p>根据这样的观察，我安利下我们的论文：</p> <p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1807.04364" target="_blank" rel="noopener noreferrer">[1807.04364] A Trilateral Weighted Sparse Coding Scheme for Real-World Image Denoising<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>. Jun Xu, Lei Zhang, David Zhang. <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2018.</p> <p>其实这真实图像去噪问题还是有一定的前景。这个问题刚开始被正式地提出，关注的人应该不多，竞争不够激烈。但是工业上对这方面的技术又有一定的需要，比如SONY, CANON, NIKON等相机厂商都需要这样的技术使得他们的相机拍摄到更清晰的图片。而中国的一些生产相机镜头的公司比如DJI也需要这样的技术。未来人工智能会越来越普及，镜头会越来越深入到人们生活的方方面面，对清晰图片的需求会越来越大。</p> <p>大家如果有兴趣，或者不知道做什么问题切入到人工智能，计算机视觉领域，那么进入到真实图像去噪这个应用应该是一个性价比很高的选择。</p> <p><a href="https://www.zhihu.com/question/66359919" target="_blank" rel="noopener noreferrer">参考文献<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/my-monster/blog/edit/master/docs/01.学术搬砖/01.降噪/02.深度学习在图像去噪方面最近有哪些进展，与传统方法相比效果如何？.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2022/10/18, 19:25:02</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/e0fcae/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">为什么深度学习去噪都采用高斯白噪声？</div></a> <a href="/pages/650608/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">训练时的学习率调整：optimizer和scheduler - 知乎</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/e0fcae/" class="prev">为什么深度学习去噪都采用高斯白噪声？</a></span> <span class="next"><a href="/pages/650608/">训练时的学习率调整：optimizer和scheduler - 知乎</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/e0fcae/"><div>
            为什么深度学习去噪都采用高斯白噪声？
            <!----></div></a> <span class="date">03-13</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/650608/"><div>
            训练时的学习率调整：optimizer和scheduler - 知乎
            <!----></div></a> <span class="date">03-13</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/6d6261/"><div>
            torch.optim.lrscheduler.MultiStepLR()用法研究 台阶阶梯学习率
            <!----></div></a> <span class="date">03-13</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1335844747@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/my-monster" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=463807063" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2023
    <span>Evan Xu | <a href="https://github.com/my-monster" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.50fadf31.js" defer></script><script src="/assets/js/2.47a03fa1.js" defer></script><script src="/assets/js/3.436c0527.js" defer></script><script src="/assets/js/11.97b02391.js" defer></script>
  </body>
</html>
