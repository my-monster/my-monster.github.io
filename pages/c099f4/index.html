<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>【转载】PyTorch 图像模型入门 (timm)：从业者指南 | Liuyuan&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="个人博客。">
    <meta name="keywords" content="个人博客。">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.6b291d34.css" as="style"><link rel="preload" href="/assets/js/app.50fadf31.js" as="script"><link rel="preload" href="/assets/js/2.47a03fa1.js" as="script"><link rel="preload" href="/assets/js/3.436c0527.js" as="script"><link rel="preload" href="/assets/js/16.d7372590.js" as="script"><link rel="prefetch" href="/assets/js/10.a34e71ca.js"><link rel="prefetch" href="/assets/js/11.97b02391.js"><link rel="prefetch" href="/assets/js/12.8e6e4c4b.js"><link rel="prefetch" href="/assets/js/13.00db5453.js"><link rel="prefetch" href="/assets/js/14.e91dd435.js"><link rel="prefetch" href="/assets/js/15.6018daa8.js"><link rel="prefetch" href="/assets/js/17.d89a4381.js"><link rel="prefetch" href="/assets/js/18.ea92a9c3.js"><link rel="prefetch" href="/assets/js/19.825ba7c0.js"><link rel="prefetch" href="/assets/js/20.8330b139.js"><link rel="prefetch" href="/assets/js/21.e65d87fa.js"><link rel="prefetch" href="/assets/js/22.84ef7201.js"><link rel="prefetch" href="/assets/js/23.c4c00f09.js"><link rel="prefetch" href="/assets/js/24.1474c794.js"><link rel="prefetch" href="/assets/js/25.607370fa.js"><link rel="prefetch" href="/assets/js/26.85790132.js"><link rel="prefetch" href="/assets/js/27.251cd882.js"><link rel="prefetch" href="/assets/js/28.87d9bae7.js"><link rel="prefetch" href="/assets/js/29.59230516.js"><link rel="prefetch" href="/assets/js/30.515bed4d.js"><link rel="prefetch" href="/assets/js/31.6eac8e06.js"><link rel="prefetch" href="/assets/js/32.e79b26fb.js"><link rel="prefetch" href="/assets/js/33.eee2be0d.js"><link rel="prefetch" href="/assets/js/34.22836300.js"><link rel="prefetch" href="/assets/js/35.1bb64409.js"><link rel="prefetch" href="/assets/js/36.7fb27be9.js"><link rel="prefetch" href="/assets/js/37.54e1ee25.js"><link rel="prefetch" href="/assets/js/38.e1fd2084.js"><link rel="prefetch" href="/assets/js/39.aa56611a.js"><link rel="prefetch" href="/assets/js/4.54ba375b.js"><link rel="prefetch" href="/assets/js/40.ae81606b.js"><link rel="prefetch" href="/assets/js/41.0b9b9a66.js"><link rel="prefetch" href="/assets/js/42.1ac387fb.js"><link rel="prefetch" href="/assets/js/43.5ce9c58b.js"><link rel="prefetch" href="/assets/js/44.750f46f0.js"><link rel="prefetch" href="/assets/js/45.d92dc275.js"><link rel="prefetch" href="/assets/js/46.22138ea3.js"><link rel="prefetch" href="/assets/js/47.c5cd0fb4.js"><link rel="prefetch" href="/assets/js/48.a6b8db9f.js"><link rel="prefetch" href="/assets/js/49.5be7f37d.js"><link rel="prefetch" href="/assets/js/5.7e641334.js"><link rel="prefetch" href="/assets/js/50.3bbc1ed4.js"><link rel="prefetch" href="/assets/js/51.69439a8b.js"><link rel="prefetch" href="/assets/js/52.6765e0d8.js"><link rel="prefetch" href="/assets/js/53.b7f818bd.js"><link rel="prefetch" href="/assets/js/54.fa6416de.js"><link rel="prefetch" href="/assets/js/55.14d3b063.js"><link rel="prefetch" href="/assets/js/56.8db2a655.js"><link rel="prefetch" href="/assets/js/57.2c520b79.js"><link rel="prefetch" href="/assets/js/58.926c69a8.js"><link rel="prefetch" href="/assets/js/59.303cfc72.js"><link rel="prefetch" href="/assets/js/6.40ea68d2.js"><link rel="prefetch" href="/assets/js/7.86d54bc0.js"><link rel="prefetch" href="/assets/js/8.fe46a857.js"><link rel="prefetch" href="/assets/js/9.dc879685.js">
    <link rel="stylesheet" href="/assets/css/0.styles.6b291d34.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Liuyuan's blog" class="logo"> <span class="site-name can-hide">Liuyuan's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/blog/" class="nav-link">blog搬运</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/my-monster/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/myself.jpg"> <div class="blogger-info"><h3>Liu Yuan</h3> <span>热爱生活！</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/blog/" class="nav-link">blog搬运</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/my-monster/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>降噪</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>pytorch学习</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/650608/" class="sidebar-link">训练时的学习率调整：optimizer和scheduler - 知乎</a></li><li><a href="/pages/6d6261/" class="sidebar-link">torch.optim.lr_scheduler.MultiStepLR()用法研究 台阶_阶梯学习率</a></li><li><a href="/pages/9b5eec/" class="sidebar-link">torch.nn.Flatten()的参数实例</a></li><li><a href="/pages/bb0c5d/" class="sidebar-link">torch.matmul()函数用法总结</a></li><li><a href="/pages/c099f4/" aria-current="page" class="active sidebar-link">【转载】PyTorch 图像模型入门 (timm)：从业者指南</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#pytorch-图像模型入门-timm-从业者指南" class="sidebar-link">PyTorch 图像模型入门 (timm)：从业者指南</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#一般用法" class="sidebar-link">一般用法</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#定制模型" class="sidebar-link">定制模型</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#特征提取" class="sidebar-link">特征提取</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#导出为不同格式" class="sidebar-link">导出为不同格式</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#兰德增幅" class="sidebar-link">兰德增幅</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#cutmix-和混合" class="sidebar-link">CutMix 和混合</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#从-torchvision-加载数据集" class="sidebar-link">从 TorchVision 加载数据集</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#从-tensorflow-数据集加载数据集" class="sidebar-link">从 TensorFlow 数据集加载数据集</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#从本地文件夹加载数据" class="sidebar-link">从本地文件夹加载数据</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#图像数据集类" class="sidebar-link">图像数据集类</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#使用示例" class="sidebar-link">使用示例</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#展望" class="sidebar-link">展望</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#使用示例-2" class="sidebar-link">使用示例</a></li><li class="sidebar-sub-header level2"><a href="/pages/c099f4/#调整学习率计划" class="sidebar-link">调整学习率计划</a></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>预训练模型处理</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>学习笔记</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-5add8e0a><div class="articleInfo" data-v-5add8e0a><ul class="breadcrumbs" data-v-5add8e0a><li data-v-5add8e0a><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-5add8e0a></a></li> <li data-v-5add8e0a><a href="/research/#学术搬砖" data-v-5add8e0a>学术搬砖</a></li><li data-v-5add8e0a><a href="/research/#pytorch学习" data-v-5add8e0a>pytorch学习</a></li></ul> <div class="info" data-v-5add8e0a><div title="作者" class="author iconfont icon-touxiang" data-v-5add8e0a><a href="https://github.com/my-monster" target="_blank" title="作者" class="beLink" data-v-5add8e0a>liuyuan</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-5add8e0a><a href="javascript:;" data-v-5add8e0a>2023-03-13</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">【转载】PyTorch 图像模型入门 (timm)：从业者指南<!----></h1>  <div class="theme-vdoing-content content__default"><h2 id="pytorch-图像模型入门-timm-从业者指南"><a href="#pytorch-图像模型入门-timm-从业者指南" class="header-anchor">#</a> PyTorch 图像模型入门 (timm)：从业者指南</h2> <p>如何在您自己的训练脚本中使用这个出色的库
<a href="https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055" target="_blank" rel="noopener noreferrer"><strong>转载链接</strong><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">PyTorch Image Models (timm)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>是一个用于最先进图像分类的库，包含图像模型、优化器、调度器、增强等的集合；它最近被评为<a href="https://medium.com/paperswithcode/papers-with-code-2021-a-year-in-review-de75d5a77b8b" target="_blank" rel="noopener noreferrer">2021 年带代码论文的热门图书馆<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>！</p> <p>虽然有越来越多的低代码和无代码解决方案可以很容易地开始将深度学习应用于计算机视觉问题，但在我目前作为 Microsoft CSE 的一员的角色中，我们经常与希望寻求量身定制的定制解决方案的客户打交道针对他们的具体问题；利用最新和最伟大的创新来超越这些服务提供的性能水平。由于新架构和培训技术被引入这个快速发展的领域的速度，无论您是初学者还是专家，都可能很难跟上最新的实践，并且在接触新事物时不知道从哪里开始变得具有挑战性视觉任务，目的是重现与学术基准中呈现的结果相似的结果。</p> <p>无论我是从头开始训练，还是针对新任务微调现有模型，以及希望利用预先存在的组件来加快我的工作流程，timm 都是我最喜欢的 PyTorch 计算机视觉库之一。然而，虽然 timm 包含用于重现<a href="https://www.image-net.org/" target="_blank" rel="noopener noreferrer">ImageNet训练结果的参考<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://github.com/rwightman/pytorch-image-models/blob/master/train.py" target="_blank" rel="noopener noreferrer">训练<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>和<a href="https://github.com/rwightman/pytorch-image-models/blob/master/validate.py" target="_blank" rel="noopener noreferrer">验证脚本，并且<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://rwightman.github.io/pytorch-image-models/" target="_blank" rel="noopener noreferrer">在官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>和<a href="https://fastai.github.io/timmdocs/" target="_blank" rel="noopener noreferrer">timmdocs 项目<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中有涵盖核心组件的文档，但由于库提供的功能数量庞大，可能很难知道在哪里在自定义用例中应用这些时开始。<a href="https://www.image-net.org/" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://rwightman.github.io/pytorch-image-models/" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://fastai.github.io/timmdocs/" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>本指南的目的是从从业者的角度探索 timm，重点介绍如何在自定义训练脚本中使用 timm 中包含的一些功能和组件。重点不是探索这些概念如何或为什么起作用，或者它们是如何在 timm 中实现的；为此，将在适当的地方提供原始论文的链接，我会推荐<a href="https://fastai.github.io/timmdocs/" target="_blank" rel="noopener noreferrer">timmdocs<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>以了解有关 timm 内部结构的更多信息。此外，本文绝不是详尽无遗的，选择的领域是基于我使用这个库的个人经验。</p> <p>此处的所有信息均基于<code>timm==0.5.4</code>撰写本文时最近发布的信息。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/d3d518dc40725ad8741f3232fc773e09.jpeg" alt=""></p> <p><a href="https://unsplash.com/@cgower" target="_blank" rel="noopener noreferrer">Christopher Gower<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>在<a href="https://unsplash.com/photos/m_HRfLhgABo" target="_blank" rel="noopener noreferrer">Unsplash<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>上的图片<a href="https://unsplash.com/photos/m_HRfLhgABo" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>虽然可以按顺序阅读这篇文章，但它也可以作为图书馆特定部分的参考。为了便于导航，下面提供了目录。</p> <ul><li><a href="#b83b"><strong>模型</strong></a><a href="#983b"><br></a>-<a href="#9388">自定义模型</a><br>
-<a href="#0583">特征提取</a><br>
-<a href="#c193">导出为不同格式</a></li> <li><a href="#4cc7"><strong>数据增强</strong></a>- <a href="#8549">RandAugment</a> <ul><li><a href="#e618">CutMix 和 MixUp</a></li></ul></li> <li><a href="#c725"><strong>数据集</strong></a><br>
-<a href="#2c65">从 TorchVision</a><br>
加载数据集-<a href="#96e0">从 TensorFlow</a><br>
加载数据集 数​​据集-<a href="#03bd">从本地文件夹加载数据集</a> <ul><li><a href="#a4d1">ImageDataset 类</a></li></ul></li> <li><a href="#18f9"><strong>优化器</strong></a><br>
-<a href="#5e2d">使用示例</a><br>
-<a href="#0afa">前瞻</a></li> <li><a href="#50f2"><strong>调度程序</strong></a>-<a href="#9ad3">使用示例</a><br>
-<a href="#65e2">调整学习率计划</a></li> <li><a href="#429c"><strong>指数移动平均模型</strong></a></li> <li><a href="#901e"><strong>把它们放在一起！</strong></a></li></ul> <p><strong><em>Tl;dr：</em></strong><em>如果您只想查看一些可以直接使用的工作代码，复制这篇文章所需的所有代码都可以在</em><a href="https://gist.github.com/Chris-hughes10/a9e5ec2cd7e7736c651bf89b5484b4a9" target="_blank" rel="noopener noreferrer"><em>此处作为 GitHub 要点</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><em>获得。</em></p> <p>timm 最受欢迎的功能之一是其庞大且不断增长的模型架构集合。其中许多模型包含预训练的权重——要么在 PyTorch 中进行本地训练，要么从其他库（如 Jax 和 TensorFlow）移植——可以轻松下载和使用。</p> <p>我们可以列出和查询集合可用模型，如下所示：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/11486427de0829bc74975a4e2606c6a3.png" alt=""></p> <p>我们还可以使用_预训练_参数将此选择过滤为具有预训练权重的模型：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/3beb0f2c86f9c6ebe747089cd25d5c90.png" alt=""></p> <p>这仍然是一个令人印象深刻的数字！如果此时您遇到一点选项瘫痪，请不要绝望！<a href="https://paperswithcode.com/" target="_blank" rel="noopener noreferrer">Papers with code的<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://paperswithcode.com/lib/timm" target="_blank" rel="noopener noreferrer">这个摘要页面<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>是一个有用的资源，可用于探索一些可用的模型并了解它们的性能，其中包含 timm 中包含的许多模型的基准和原始论文的链接。<a href="https://paperswithcode.com/" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>为简单起见，让我们在这里坚持使用熟悉的、久经考验的 ResNet 模型系列。我们可以通过提供通配符字符串来列出可用的不同 ResNet 变体，该字符串将用作基于模型名称的过滤器：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/000a8205d48b333ec4200abae2597bbb.png" alt=""></p> <p>正如我们所看到的，仍然有很多选择！现在，让我们探讨一下如何从这个列表中创建模型。</p> <h2 id="一般用法"><a href="#一般用法" class="header-anchor">#</a> 一般用法</h2> <p>创建模型的最简单方法是使用<code>create_model</code>; 可用于在 timm 库中创建任何模型的工厂函数。</p> <p>让我们通过创建一个 Resnet-D 模型来证明这一点，正如<a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noopener noreferrer">_卷积神经网络图像分类技巧袋论文_中<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>所介绍的那样；这是对 ResNet 架构的修改，它利用平均池调整进行下采样。这在很大程度上是一个随意的选择，此处演示的功能应该适用于 timm 中包含的大多数模型。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/0b63792cd552ff83a191f9b3501b3ccf.png" alt=""></p> <p>正如我们所见，这只是一个常规的 PyTorch 模型。</p> <p>为了帮助我们更多地了解如何使用这个模型，我们可以访问它的配置，其中包含诸如应该用于规范化输入数据的统计信息、输出类的数量和网络分类部分的名称等信息.</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/2eb4c26ac221c451d54e49fb6618923d.png" alt=""></p> <p><strong>具有不同数量输入通道的图像的预训练模型</strong></p> <p>timm 模型的一个鲜为人知但非常有用的特性是它们能够处理具有不同数量通道的输入图像，这给大多数其他库带来了问题；<a href="https://fastai.github.io/timmdocs/models#So-how-is-timm-able-to-load-these-weights?" target="_blank" rel="noopener noreferrer">这里<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>描述了一个很好的解释这是如何工作的。直观上，timm 通过对少于 3 个通道的初始卷积层的权重求和，或者智能地将这些权重复制到所需数量的通道来做到这一点。</p> <p>_我们可以通过将in_chans_参数传递给 来指定输入图像的通道数<code>create_model</code>。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/ce541a776b67fc7e60896d185b6daf24.png" alt=""></p> <p>在这种情况下使用随机张量表示单通道图像，我们可以看到模型已经处理了图像并返回了预期的输出形状。</p> <p>重要的是要注意，虽然这使我们能够使用预训练模型，但输入与训练模型的图像有很大不同。因此，我们不应该期待相同水平的性能，并在将模型用于任务之前在新数据集上微调模型！</p> <h2 id="定制模型"><a href="#定制模型" class="header-anchor">#</a> <strong>定制模型</strong></h2> <p>除了使用库存架构创建模型外，<code>create_model</code>还支持许多参数，使我们能够为我们的任务定制模型。</p> <p>支持的参数可能取决于底层模型架构，其中一些参数例如：</p> <ul><li><strong>global_pool</strong>：确定在最终分类层之前要使用的全局池的类型</li></ul> <p>特定于模型。在这种情况下，这取决于架构是否采用全局池化层。因此，虽然我们可以将它与类似 ResNet 的模型一起使用，但将它与不使用平均池化的<a href="https://arxiv.org/abs/2010.11929v2" target="_blank" rel="noopener noreferrer">ViT一起使用是没有意义的。<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>虽然有些参数是特定于模型的，但参数例如：</p> <ul><li><strong>drop_rate</strong>：设置训练的辍学率（默认值：`0`）</li> <li><strong>num_classes</strong> : 类对应的输出神经元数量</li></ul> <p>几乎可以用于所有型号。</p> <p>在我们探索一些我们可以做到这一点的方法之前，让我们检查一下我们当前模型的默认架构。</p> <p><strong>更改班级数量</strong></p> <p>检查我们之前看到的模型配置，我们可以看到我们网络的分类头名称是_fc_。我们可以使用它来直接访问相应的模块。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/4f55717814b5e99b424be3f2f131a2a7.png" alt=""></p> <p>但是，这个名称可能会根据所使用的模型架构而改变。为了为不同的模型提供一致的接口，timm 模型有<code>get_classifier</code> 方法，我们可以使用它来检索分类头，而无需查找模块名称。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/397faad5362a0c6d8666c9758fc9b586.png" alt=""></p> <p>正如预期的那样，这将返回与之前相同的线性层。</p> <p>由于这个模型是在 ImageNet 上预训练的，我们可以看到最后一层输出了 1000 个类。我们可以用_num_classes_参数改变它：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/3a668c26d96e4971ef968d887671acca.png" alt=""></p> <p>检查分类器，我们可以看到 timm 已经用一个新的、未经训练的、具有所需类别数量的线性层替换了最后一层；准备微调我们的数据集！</p> <p>如果我们想避免完全创建最后一层，我们可以将类的数量设置为 0，这将创建一个具有恒等函数的模型作为最后一层；这对于检查倒数第二层的输出很有用。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/343c7fa455fb803fb66cd31096f142cc.png" alt=""></p> <p><strong>全局合并选项</strong></p> <p>从我们模型的配置中，我们还可以看到_pool_size_已设置，通知我们在分类器之前使用了全局池化层。我们可以按如下方式检查：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/58badf1196cce02790d150838f3b3827.png" alt=""></p> <p>在这里，我们可以看到这返回了一个 的实例<code>SelectAdaptivePool2d</code>，它是 timm 提供的自定义层，它支持不同的池化和展平配置。在撰写本文时，支持的池化选项有：</p> <ul><li><em>avg</em>：平均池化</li> <li><em>max</em> : 最大池化</li> <li>_avgmax：_平均池化和最大池化的总和，按 0.5 重新缩放</li> <li>_catavgmax：_沿特征维度的平均和最大池化输出的串联。请注意，这将使特征维度加倍。</li> <li>_'' :_没有使用池化，池化层被Identity操作代替</li></ul> <p>我们可以可视化不同池化选项的输出形状，如下所示：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/e20a1f7f61675a36824ebdca8df24be9.png" alt=""></p> <p><strong>修改现有模型</strong></p> <p>我们还可以使用以下方法修改现有模型的分类器和池化层<code>reset_classifier</code> ：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/9760579e59605ba99ffa9c1a204f09fb.png" alt=""></p> <p><strong>创建一个新的分类头</strong></p> <p>虽然已经证明使用单个线性层作为我们的分类器足以获得良好的结果，但在对下游任务微调模型时，我经常发现使用稍大的头部可以提高性能。让我们探索如何进一步修改我们的 ResNet 模型。</p> <p>首先，让我们像以前一样创建我们的 ResNet 模型，指定我们想要 10 个类。由于我们使用的是更大的头部，因此我们使用_catavgmax_进行池化，以便我们提供更多信息作为分类器的输入。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/d131aaa798d6c417ddd4a035462de608.png" alt=""></p> <p>从现有的分类器中，我们可以得到输入特征的数量：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/5d32cf0984095ded9570dc705074397d.png" alt=""></p> <p>现在，我们可以通过直接访问分类器，用修改后的分类头替换最后一层。在这里，分类头的选择有些随意。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/c5049489023b64b7d0cd75ea20406c00.png" alt=""></p> <p>使用虚拟输入测试模型，我们得到预期形状的输出。现在，我们修改后的模型可以训练了！</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/93ff6a7f7c77ca90ab5a0cd309cf022a.png" alt=""></p> <h2 id="特征提取"><a href="#特征提取" class="header-anchor">#</a> 特征提取</h2> <p>timm 模型还具有用于获取各种类型的中间特征的一致机制，这对于将架构用作下游任务的特征提取器非常有用；比如<a href="https://ieeexplore.ieee.org/document/8099589" target="_blank" rel="noopener noreferrer">在物体检测中创建特征金字塔<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p><a href="https://www.robots.ox.ac.uk/~vgg/data/pets/" target="_blank" rel="noopener noreferrer">让我们使用来自Oxford pets 数据集<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的图像可视化这是如何工作的。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/d19e038e9f2614ae3b343bfe26bbbdb0.png" alt=""></p> <p>我们可以将其转换为张量，并将通道转置为 PyTorch 期望的格式：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/375090ac979689588232f688806bf083.png" alt=""></p> <p>再一次，让我们创建我们的 ResNet-D 模型：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/bff4b23a44080ef22af167a70b1391ec.png" alt=""></p> <p>如果我们只对最终的特征图感兴趣——在这种情况下，即池化之前最终卷积层的输出——我们可以使用该<code>forward_features</code> 方法绕过全局池化层和分类层。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/66edd69cf7f85365daaee10a3848130e.png" alt=""></p> <p>我们可以在下面想象一下：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/6b35e816dfcd5ff819a565b300cfc060.png" alt=""></p> <p><strong>多个特征输出</strong></p> <p>虽然前向特征方法可以方便地检索最终特征图，但 timm 还提供了使我们能够使用模型作为特征主干的功能，为选定级别输出特征图。</p> <p>我们可以通过在创建模型时使用参数_features_only=True_来指定我们希望将模型用作特征主干。默认情况下，大多数模型（并非所有模型都有那么多）将输出 5 个步幅，第一个从 2 开始（但有些从 1 或 4 开始）。</p> <p>可以使用_out_indices_和_output_stride_参数修改特征级别的索引和步幅数，如<a href="https://rwightman.github.io/pytorch-image-models/feature_extraction/#multi-scale-feature-maps-feature-pyramid" target="_blank" rel="noopener noreferrer">文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中所示。</p> <p>让我们看看它如何与我们的 ResNet-D 模型一起使用。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/fdab1ac95ded8a0fa7b20a8277d144f5.png" alt=""></p> <p>如下所示，我们可以获得有关返回的特征的更多信息，例如具体的模块名称、减少的特征和通道数：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/3942fbe1cadb9638a6c81150f7c25606.png" alt=""></p> <p>现在，让我们通过特征提取器传递图像并探索输出。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/37d711063df14bca22533a129da48f6c.png" alt=""></p> <p>不出所料，返回了 5 个特征图。检查形状，我们可以看到通道数与我们预期的一致：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/761060d0cb9cca9c5c65dfb7b0fe6947.png" alt=""></p> <p>可视化每个特征图，我们可以看到图像正在逐渐下采样，正如我们所期望的那样。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/aeb8aecd15f69924090cdc1ee0ffef96.png" alt=""></p> <p><img src="https://img-blog.csdnimg.cn/img_convert/d040212474cf73b3a1f4d60f22038799.png" alt=""></p> <p><strong>使用 Torch FX</strong></p> <p><a href="https://pytorch.org/vision/stable/index.html" target="_blank" rel="noopener noreferrer">TorchVision<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>最近发布了一个名为 FX 的新实用程序，它使得在 PyTorch 模块的前向传递期间更容易访问输入的中间转换。这是通过象征性地跟踪 forward 方法来生成一个图来完成的，其中每个节点代表一个操作。由于节点被赋予了人类可读的名称，因此很容易准确地指定我们想要访问的节点。<a href="https://pytorch.org/docs/stable/fx.html#module-torch.fx" target="_blank" rel="noopener noreferrer">FX在文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>和<a href="https://pytorch.org/blog/FX-feature-extraction-torchvision/" target="_blank" rel="noopener noreferrer">这篇博<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>文中有更详细的描述。</p> <p><strong>注意</strong>：在撰写本文时，动态控制流在使用 FX 时还不能用静态图来表示。</p> <p>由于 timm 中的几乎所有模型都是符号可追溯的，我们可以使用 FX 来操纵这些模型。让我们探索如何使用 FX 从 timm 模型中提取特征。</p> <p>首先，让我们从 TorchVision 导入一些辅助方法：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/2a63aa02a8a5c1e08fe1fcc2b6bc7631.png" alt=""></p> <p>现在，我们重新创建带有分类头的 ResNet-D 模型，并使用_可导出_参数来确保模型是可追踪的。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/2598f412a0ca1dc12b8040682ad0fd6e.png" alt=""></p> <p>现在，我们可以使用该<code>get_graph_nodes</code>方法按执行顺序返回节点名称。由于模型被跟踪两次，在训练和评估模式下，都会返回两组节点名称。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/95ad8339cb9d97a640ed1ef1e2d02e0c.png" alt=""></p> <p>使用 FX，可以轻松访问来自任何节点的输出。_让我们选择layer1_中的第二个激活。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/c36159f311a0e200cf3a20ea18451229.png" alt=""></p> <p>使用<code>create_feature_extractor</code>，我们可以在该点“切割”模型，如下所示：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/8293ddd4cf162b75342b6e7b7a085e45.png" alt=""></p> <p>现在，通过我们的特征提取器传递图像，这将返回一个张量字典。然后我们可以像以前一样将其可视化：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/c8f9271cdec8f3805dd4cfec8b6397e2.png" alt=""></p> <h2 id="导出为不同格式"><a href="#导出为不同格式" class="header-anchor">#</a> 导出为不同格式</h2> <p>训练后，通常建议将模型导出为优化格式以进行推理；PyTorch 有多种选择可以做到这一点。由于几乎所有 timm 模型都是可编写脚本和可跟踪的，因此我们可以使用这些格式。</p> <p>让我们检查一些可用的选项。</p> <p><strong>导出到 TorchScript</strong></p> <p>TorchScript 是一种从 PyTorch 代码创建可序列化和可优化模型的方法；任何 TorchScript 程序都可以从 Python 进程中保存并加载到没有 Python 依赖性的进程中。</p> <p>我们可以通过两种不同的方式将模型转换为 TorchScript：</p> <ul><li><em>Tracing</em>：运行代码，记录发生的操作并构造包含这些操作的 ScriptModule。控制流或动态行为（如 if/else 语句）被删除。</li> <li><em>脚本</em>：使用脚本编译器对 Python 源代码进行直接分析，将其转换为 TorchScript。这保留了动态控制流，并且适用于不同大小的输入。</li></ul> <p>有关 TorchScript<a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer">的更多信息，请参阅文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>和<a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html" target="_blank" rel="noopener noreferrer">本教程<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>由于大多数 timm 模型都可以编写脚本，因此让我们使用脚本来导出我们的 ResNet-D 模型。我们可以设置层配置，以便在创建我们的模型时使用_脚本化参数对模型进行 jit 脚本化。_</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/598e84cb3af2d76acbffc4adcad6f35b.png" alt=""></p> <p>重要的是<code>model.eval()</code>在导出模型之前调用，将模型置于推理模式，因为 dropout 和 batchnorm 等运算符的行为因模式而异。</p> <p>我们现在可以验证我们是否能够编写脚本并使用我们的模型。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/2365e757f93e7012e8c8672ad59cfed9.png" alt=""></p> <p><strong>导出到 ONNX</strong></p> <p><a href="https://onnx.ai/" target="_blank" rel="noopener noreferrer">Open Neural Network eXchange (ONNX)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>是一种用于表示机器学习模型的开放标准格式。</p> <p>我们可以使用该<code>torch.onnx</code>模块将timm模型导出到ONNX；使它们能够被支持 ONNX 的许多运行时中的任何一个使用。如果<code>torch.onnx.export()</code>用一个还不是 ScriptModule 的模块调用，它首先执行等同于<code>torch.jit.trace()</code>; 它使用给定的参数执行一次模型并记录在该执行期间发生的所有操作。这意味着如果模型是动态的，例如，根据输入数据更改行为，则导出的模型将不会捕获此动态行为。同样，迹线可能仅对特定输入大小有效。</p> <p>可以<a href="https://pytorch.org/docs/master/onnx.html" target="_blank" rel="noopener noreferrer">在文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中找到有关 ONNX 的更多详细信息。</p> <p>为了能够以 ONNX 格式导出 timm 模型，我们可以在创建模型时使用 exportable_参数_，以确保模型是可追踪的。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/ab7bea1ee10e33ca96127b90e7fb3d30.png" alt=""></p> <p>我们现在可以<code>torch.onnx.export</code>用来跟踪和导出我们的模型：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/e4fa2e4f842037c291077ed5fa3a54fe.png" alt=""></p> <p><code>check_model</code>我们现在可以使用该函数验证我们的模型是否有效。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/15ecbd4730eaae048eb8dcb4f021be8c.png" alt=""></p> <p>由于我们指定我们的模型应该是可追踪的，因此我们也可以手动执行追踪，如下所示。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/4254854a1c74959c923f7009b8e6ddc6.png" alt=""></p> <p>timm 包含许多数据增强转换，可以将它们链接在一起以制作增强管道；与 TorchVision 类似，这些管道需要 PIL 图像作为输入。</p> <p>最简单的入门方法是使用<code>create_transform</code>工厂函数，让我们在下面探讨如何使用它。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/e4a7239d84c7a515ba36076383863263.png" alt=""></p> <p>在这里，我们可以看到这已经创建了一些基本的增强管道，包括调整大小、归一化和将图像转换为张量。<em>正如我们所料，当我们设置is_training=True_时，我们可以看到额外的转换，例如水平翻转和颜色抖动。这些增强的幅度可以通过_hflip</em>、_vflip_和_color_jitter_等参数来控制。</p> <p>我们还可以看到，用于调整图像大小的方法也因我们是否在训练而异。虽然在验证期间使用了标准的_Resize_和_CenterCrop_，但在训练期间使用了_RandomResizedCropAndInterpolation_，下面让我们看看它做了什么。由于 timm 中此变换的实现使我们能够设置不同的图像插值方法；这里我们选择随机选择插值。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/305e2c2bb6f33b0097918a16051ce15f.png" alt=""></p> <p>多次运行转换，我们可以观察到图像被截取了不同的裁剪。虽然这在训练过程中是有益的，但这可能会使评估过程中的任务变得更加困难。</p> <p>根据图像的类型，这种类型的变换可能会导致图片的主题从图像中被裁剪掉；如果我们查看第一行中的第二张图片，我们可以看到一个例子！虽然这不应该是一个大问题，如果它不经常发生，我们可以通过调整 scale 参数来避免这种情况：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/11cf93573d2b1bed81df9867dd921c31.png" alt=""></p> <h2 id="兰德增幅"><a href="#兰德增幅" class="header-anchor">#</a> <strong>兰德增幅</strong></h2> <p>开始一项新任务时，可能很难知道要使用哪些增强功能以​​及使用的顺序；随着现在可用的增强数量，组合的数量是巨大的！</p> <p>通常，一个好的起点是使用在其他任务上表现良好的增强管道。其中一个策略是 RandAugment，这是一种自动数据增强方法，它从一组增强中统一采样操作——例如均衡、旋转、曝光、颜色抖动、色调分离、改变对比度、改变亮度、改变锐度、剪切和平移——并应用其中一些顺序；有关更多信息，请参阅<a href="https://arxiv.org/abs/1909.13719" target="_blank" rel="noopener noreferrer">原始论文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>然而，timm 中提供的实现有几个关键差异，timm 的创建者 Ross Wightman 在<a href="https://arxiv.org/pdf/2110.00476v1.pdf" target="_blank" rel="noopener noreferrer">ResNets Strike Back 论文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的附录中对其进行了最好的描述，我将其解释如下：</p> <blockquote><p>原始的 RandAugment 规范有两个超参数，M 和 N；其中 M 是失真幅度，N 是对每个图像均匀采样和应用的失真数。RandAugment 的目标是 M 和 N 都是人类可解释的。</p> <p>然而，[在最初的实现中] M 的情况并非如此。几个增强的尺度向后或不在范围内单调增加，因此增加 M 不会增加所有增强的强度。</p></blockquote> <p>在最初的实现中，虽然一些增强随着 M 的增加而增强，但其他增强会减少或完全删除，这样每个 M 基本上代表自己的策略。</p> <blockquote><p>timm 中的实现试图通过添加“增加”模式 [默认启用] 来改善这种情况，其中所有增强强度都随幅度增加。</p></blockquote> <p>这使得增加 M 更加直观，因为所有增强现在都应该随着 M 的相应减少/增加而减少/增加强度。</p> <blockquote><p>[此外，] timm 添加了一个 MSTD 参数，该参数将具有指定标准偏差的高斯噪声添加到每个失真应用的 M 值中。如果 MSTD 设置为“-inf”，则对于每个失真从 0-M 统一采样 M。</p> <p>在 timm 的 RandAugment 中注意减少对图像均值的影响，归一化参数可以作为参数传递，这样所有可能引入边界像素的增强都可以使用指定的均值，而不是默认为 0 或其他硬编码元组实施。</p> <p>[最后，] 默认情况下排除 Cutout 以支持单独使用 timm 的随机擦除实现*，这<br>
对增强图像的均值和标准差影响较小。</p></blockquote> <p><a href="https://fastai.github.io/timmdocs/RandomErase" target="_blank" rel="noopener noreferrer">*这里详细探讨了<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>timm 中随机擦除的实现。</p> <p>现在我们了解了 RandAugment 是什么，让我们看看如何在扩充管道中使用它！</p> <p>在 timm 中，我们使用配置字符串定义 RandAugment 策略的参数；由破折号 ( <code>-</code>)分隔的多个部分组成</p> <p>第一部分定义了 rand augment 的特定变体（目前仅<code>rand</code>支持）。可以按任何顺序放置的其余部分是：</p> <ul><li><strong>m</strong> ( <em>integer</em> ): 随机增加的幅度</li> <li><strong>n</strong>（<em>整数</em>）：每个图像选择的变换操作数，这是可选的，默认设置为 2</li> <li><strong>mstd (</strong> <em>float</em> ): 应用的幅度噪声的标准偏差</li> <li><strong>mmax</strong>（<em>整数</em>）：将幅度的上限设置为默认值 10 以外的值</li> <li><strong>w</strong> ( <em>integer</em> ): 概率权重指数（影响操作选择的一组权重的指数）</li> <li><strong>inc</strong> ( <em>bool — {0, 1}</em> )：使用严重程度随幅度增加的增强，这是可选的，默认值为 0例如：</li> <li><code>rand-m9-n3-mstd0.5</code>：导致 RandAugment 幅度为 9，每个图像 3 个增强，mstd 0.5</li> <li><code>rand-mstd1-w0</code>：导致 mstd 1.0，权重 0，默认 magnitude m 为 10，每个图像有 2 个增强</li></ul> <p>将配置字符串传递给<code>create_transform</code>，我们可以看到这是由<code>RandAugment</code>对象处理的，我们可以看到所有可用操作的名称：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/2eaeb379adf5597147f44cc801f35939.png" alt=""></p> <p>我们还可以使用<code>rand_augment_transform</code>函数创建此对象以在自定义管道中使用，如下所示：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/6946ea7b951d1c20243d57f196413a70.png" alt=""></p> <p>让我们将此策略应用于图像以可视化一些转换。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/023328491c3415c7dc4f0887e194f6f3.png" alt=""></p> <p>从这里，我们可以看到使用 RandAugment 给了我们很多图像的变化！</p> <h2 id="cutmix-和混合"><a href="#cutmix-和混合" class="header-anchor">#</a> <strong>CutMix 和混合</strong></h2> <p>timm 使用类提供了<a href="https://arxiv.org/abs/1905.04899" target="_blank" rel="noopener noreferrer">CutMix<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>和<a href="https://arxiv.org/abs/1710.09412" target="_blank" rel="noopener noreferrer">Mixup<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>扩充的灵活实现<code>Mixup</code>；它处理两种增强并提供在它们之间切换的选项。</p> <p>使用<code>Mixup,</code>我们可以从各种不同的混合策略中进行选择：</p> <ul><li><em>batch</em>：CutMix 与 Mixup 选择、lambda 和 CutMix 区域采样按批次执行</li> <li><em>pair</em>：混合、lambda 和区域采样在批次中的采样对上执行</li> <li><em>elem</em>：混合、lambda 和区域采样在批次内按图像执行</li> <li><em>half</em>：与 elementwise 相同，但每个混合对中的一个被丢弃，以便每个样本每个 epoch 看到一次</li></ul> <p>让我们想象一下这是如何工作的。为此，我们需要创建一个 DataLoader，遍历它并将扩充应用于批处理。我们将再次使用 Pets 数据集中的图像。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/100c3e897b008f510b74dedf85051a7d.png" alt=""></p> <p>使用 TorchVision 和<a href="https://fastai.github.io/timmdocs/mixup_cutmix" target="_blank" rel="noopener noreferrer">timmdocs<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的辅助函数，我们可以在不应用增强的情况下可视化我们批次中的图像：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/9c89c029ba1994adcd4b46a3508a0ec9.png" alt=""></p> <p>现在，让我们创建我们的 MixUp 转换！<code>Mixup</code>支持以下参数：</p> <ul><li><strong>mixup_alpha</strong> ( <em>float</em> ): 混合 alpha 值，如果 &gt; 0 则混合有效，（默认值：1）</li> <li><strong>cutmix_alpha</strong> ( <em>float</em> )：cutmix alpha 值，如果 &gt; 0，则 cutmix 处于活动状态。（默认值：0）</li> <li><strong>cutmix_minmax</strong> ( <em>List[float]</em> )：cutmix 最小/最大图像比率，cutmix 处于活动状态，如果不是 None，则使用此 vs alpha。</li> <li><strong>prob</strong> ( <em>float</em> ): 每个批次或元素应用 mixup 或 cutmix 的概率（默认值：1）</li> <li><strong>switch_prob</strong> ( <em>float</em> )：当两者都处于活动状态时切换到 cutmix 而不是 mixup 的概率（默认值：0.5）</li> <li><strong>模式</strong>（<em>str</em>）：如何应用 mixup/cutmix 参数（默认值：<em>batch</em>）</li> <li><strong>label_smoothing</strong> ( <em>float</em> )：应用于混合目标张量的标签平滑量（默认值：0.1）</li> <li><strong>num_classes</strong> ( <em>int</em> ): 目标变量的类数</li></ul> <p>让我们定义一组参数，以便我们将 mixup 或 cutmix 应用于一批图像，并以 1 的概率交替，并使用它们来创建我们的“Mixup”转换：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/2f5de61626a9efcedff1b441b1c71ccf.png" alt=""></p> <p>由于 mixup 和 cutmix 发生在一批图像上，我们可以在应用增强之前将批次放在 GPU 上以加快处理速度！在这里，我们可以看到 mixup 已应用于这批图像。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/f1e41d3adbe6e7558e83ad6fa9ec86d9.png" alt=""></p> <p><img src="https://img-blog.csdnimg.cn/img_convert/1dd76acd358a8752c9f8f8757b5e3e88.png" alt=""></p> <p>再次运行增强，我们可以看到，这次应用了 CutMix。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/13e5d3ec445131acab9e00a6280baf0f.png" alt=""></p> <p>从彼此上方打印的标签中，我们可以观察到我们也可以<code>Mixup</code>用于标签平滑！</p> <p>timm 提供了许多有用的实用程序来处理不同类型的数据集。最简单的入门方法是使用该<code>create_dataset</code>函数，它将为我们创建一个合适的数据集。</p> <p><code>create_dataset</code>总是需要两个参数：</p> <ul><li><em>name</em>：我们要加载的数据集的名称</li> <li>_root：_数据集在本地文件系统上的根文件夹</li></ul> <p>但有额外的关键字参数可用于指定选项，例如我们是否要加载训练集或验证集。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/1564d4d64447c358c580680e6b60b23b.png" alt=""></p> <p>我们还可以使用<code>create_dataset</code>, 从几个不同的地方加载数据：</p> <ul><li><a href="https://pytorch.org/vision/0.11/datasets.html" target="_blank" rel="noopener noreferrer">TorchVision<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中可用的数据集<a href="https://pytorch.org/vision/0.11/datasets.html" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://www.tensorflow.org/datasets" target="_blank" rel="noopener noreferrer">TensorFlow 数据<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>集中可用的数据集<a href="https://www.tensorflow.org/datasets" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>存储在本地文件夹中的数据集</li></ul> <p>让我们探讨其中的一些选项。</p> <h2 id="从-torchvision-加载数据集"><a href="#从-torchvision-加载数据集" class="header-anchor">#</a> 从 TorchVision 加载数据集</h2> <p>要加载 TorchVision 包含的数据集，我们只需<code>torch/</code>在我们希望加载的数据集名称前指定前缀即可。如果数据在文件系统中不存在，我们可以通过设置_download=True_来下载这些数据。此外，我们在这里指定要使用_split_参数加载训练数据集。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/eff2d1687aee390adc20f29369498a50.png" alt=""></p> <p>检查类型，我们可以看到这是一个 TorchVision 数据集。我们可以像往常一样使用索引访问它：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/d276415ca7cd02c0ef51b87c98e2f2df.png" alt=""></p> <h2 id="从-tensorflow-数据集加载数据集"><a href="#从-tensorflow-数据集加载数据集" class="header-anchor">#</a> 从 TensorFlow 数据集加载数据集</h2> <p>除了通过 TorchVision 使用 PyTorch 时通常可用的数据集外，timm 还使我们能够从 TensorFlow 数据集下载和使用数据集；为我们包装底层<code>tfds</code>对象。</p> <p>从 TensorFlow 数据集加载时，建议我们设置几个额外的参数，本地或 TorchVision 数据集不需要这些参数：</p> <ul><li><strong>batch_size</strong>：这用于确保批量大小除以分布式训练期间所有节点的样本总数</li> <li><strong>is_training</strong>：如果设置，数据集将被打乱。请注意，这与设置_拆分不同_</li></ul> <p>虽然此包装器从 TFDS 数据集中返回解压缩的图像示例，但我们需要的任何增强和批处理仍由 PyTorch 处理。</p> <p>在这种情况下，我们在数据集的名称前加上<code>tfds/</code>. 可在<a href="https://www.tensorflow.org/datasets/catalog/overview#image_classification" target="_blank" rel="noopener noreferrer">此处<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>找到用于图像分类的可用数据集列表。对于这个例子，我们将任意选择_beans_数据集。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/1faa725947b90933a2b7dd50edf43b21.png" alt=""></p> <p>我们还可以看到，对于_split_参数，我们指定了一个<code>tfds</code> 拆分字符串，如此<a href="https://www.tensorflow.org/datasets/splits" target="_blank" rel="noopener noreferrer">处<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>所述。</p> <p>检查我们的数据集，我们可以看到底层的 TensorFlow 数据集已被包装在一个<code>IterableImageDataset</code>对象中。作为一个可迭代的数据集，它不支持索引——看<a href="https://pytorch.org/docs/stable/data.html#dataset-types" target="_blank" rel="noopener noreferrer">这里<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的区别——所以为了从这个数据集中查看图像，我们必须首先创建一个迭代器。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/0604ca9d072a23f0102ad554d13d3936.png" alt=""></p> <p>我们现在可以使用此迭代器按顺序检查我们的图像和标签，如下所示。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/0109145474a642e05e79ee25e2e241c8.png" alt=""></p> <p>我们可以看到我们的图片已经正确加载了！</p> <h2 id="从本地文件夹加载数据"><a href="#从本地文件夹加载数据" class="header-anchor">#</a> 从本地文件夹加载数据</h2> <p>我们还可以从本地文件夹加载数据，在这些情况下，我们只需使用空字符串 (<code>''</code>) 作为数据集名称。</p> <p>除了能够从 ImageNet 风格的文件夹层次结构中加载之外，<code>create_dataset</code>还可以让我们从一个或多个 tar 存档中提取；我们可以使用它来避免解压缩存档！例如，我们可以在<a href="https://github.com/fastai/imagenette" target="_blank" rel="noopener noreferrer">Imagenette 数据集<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>上进行尝试。</p> <p>此外，到目前为止，我们一直在加载原始图像，所以让我们也使用_transform_参数来应用一些转换；<code>create_transform</code>在这里，我们可以使用我们之前看到的函数快速创建一些合适的转换！</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/28e756e30a826bfbf307d85a7db6a3a9.png" alt=""></p> <p>通过检查图像的耻辱，我们可以看到我们的变换已经应用。</p> <h2 id="图像数据集类"><a href="#图像数据集类" class="header-anchor">#</a> 图像数据集类</h2> <p>正如我们所见，该<code>create_dataset</code>函数提供了很多选项来处理不同类型的数据。timm 能够提供这种灵活性的原因是在可能的情况下使用 TorchVision 中提供的现有数据集类，并提供一些额外的实现——<code>ImageDataset</code>并且<code>IterableImageDataset</code>可以在广泛的场景中使用。</p> <p>本质上，<code>create_dataset</code>通过选择合适的类为我们简化了这个过程，但有时我们可能希望直接使用底层组件。</p> <p>我最常使用的实现是<code>ImageDataset</code>，它类似于<a href="https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html" target="_blank" rel="noopener noreferrer"><em>torchvision.datasets.ImageFolder</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，但有一些额外的功能。让我们探索如何使用它来加载我们解压缩的 imagenette 数据集。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/2702066f7d8a3489542eaa3dd6a12448.png" alt=""></p> <p>的灵活性的关键在于<code>ImageDataset</code>它索引和加载样本的方式被抽象到一个<code>Parser</code>对象中。</p> <p>timm 包含几个解析器，包括从文件夹、tar 文件和 TensorFlow 数据集读取图像的解析器。解析器可以作为参数传递给数据集，我们可以直接访问解析器。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/ac0ca636ee57b0984c30abebd8047d15.png" alt=""></p> <p>在这里，我们可以看到默认的解析器是<code>ParserImageFolder</code>. 解析器还包含有用的信息，例如类查找，我们可以如下所示访问这些信息。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/333c8906ebdd6f38cef024ac93d24d40.png" alt=""></p> <p>我们可以看到此解析器已将原始标签转换为整数，可以将其提供给我们的模型。</p> <p><strong>手动选择解析器——tar 示例</strong></p> <p>因此，除了选择合适的类外，<code>create_dataset</code>还负责选择正确的解析器。再次考虑压缩的 Imagenette 数据集，我们可以通过手动选择<code>ParserImageInTar</code>解析器并覆盖<code>ImageDataset</code>的默认解析器来获得相同的结果。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/536c5d1aafa1149f5c3b856c25c5a0ee.png" alt=""></p> <p>检查第一个示例，我们可以验证它是否已正确加载。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/cd0d6f7231eead30811ae0e86f1996f3.png" alt=""></p> <p><strong>创建自定义解析器</strong></p> <p>不幸的是，数据集的结构并不总是像 ImageNet；也就是说，具有以下结构：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>root/class_1/xx1.jpg   
root/class_1/xx2.jpg   
root/class_2/xx1.jpg   
root/class_2/xx2.jpg
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>对于这些数据集，<code>ImageDataset</code>开箱即用。虽然我们总是可以实现自定义数据集来处理这个问题，但这可能具有挑战性，具体取决于数据的存储方式。另一种选择是编写自定义解析器以与<code>ImageDataset</code>.</p> <p>例如，让我们考虑<a href="https://www.robots.ox.ac.uk/~vgg/data/pets/" target="_blank" rel="noopener noreferrer">Oxford 宠物数据集<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，其中所有图像都位于一个文件夹中，并且类名（在本例中为每个品种的名称）包含在文件名中。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/3d5a2089f7a50b9e6faddf3641c94bf1.png" alt=""></p> <p>在这种情况下，由于我们仍在从本地文件系统加载图像，因此对<code>ParserImageFolder</code>. 让我们看看它是如何实现的以获取灵感。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/9d91c34ab416fc712b7e38abcb87e101.png" alt=""></p> <p>从这里，我们可以看到 ParserImageFolder 做了几件事：</p> <ul><li>为类创建映射</li> <li>实现<code>__len__</code>返回样本数</li> <li>实现<code>_filename</code>返回样本的文件名，并带有确定它应该是绝对路径还是相对路径的选项</li> <li>实现<code>__getitem__</code>返回样本和目标。</li></ul> <p>现在我们了解了我们必须实现的方法，我们可以基于此创建我们自己的实现！在这里，我使用了标准库中的<a href="https://docs.python.org/3/library/pathlib.html" target="_blank" rel="noopener noreferrer"><em>pathlib</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>来提取类名并处理我们的路径；因为我发现它比<code>os</code>.</p> <p>我们现在可以将解析器的一个实例传递给<code>ImageDataset</code>，这应该使它能够正确加载宠物数据集！</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/4c4cbf9c5c24fcc01115a524ed900396.png" alt=""></p> <p>让我们通过检查第一个示例来验证我们的解析器是否正常工作。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/aa3d2eeac3d5e2ef9c37688990649ece.png" alt=""></p> <p>由此看来，我们的解析器似乎成功了！此外，与默认解析器一样，我们可以检查已执行的类映射。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/330608893cfe4b6d9a9690bf2d09a551.png" alt=""></p> <p>在这个简单的示例中，创建自定义数据集实现只会稍微多一些努力。但是，希望这有助于说明编写自定义解析器并使其与<code>ImageDataset</code>!</p> <p>timm 具有大量优化器，其中一些优化器不作为 PyTorch 的一部分提供。除了使访问熟悉的优化器（如<a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html" target="_blank" rel="noopener noreferrer">SGD<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>、<a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" target="_blank" rel="noopener noreferrer">Adam<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>和<a href="https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html#torch.optim.AdamW" target="_blank" rel="noopener noreferrer">AdamW<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> ）变得容易之外，一些值得注意的内容包括：</p> <ul><li><strong>AdamP</strong>：<a href="https://arxiv.org/abs/2006.08217" target="_blank" rel="noopener noreferrer">在本文中描述<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>RMSPropTF</strong>：基于原始 TensorFlow 实现的<a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="noopener noreferrer">RMSProp实现，以及<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://github.com/pytorch/pytorch/issues/23796" target="_blank" rel="noopener noreferrer">此处讨论的其他小调整<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。根据我的经验，这通常会导致比 PyTorch 版本更稳定的训练</li> <li><strong>LAMB ：</strong> <a href="https://nvidia.github.io/apex/optimizers.html#apex.optimizers.FusedLAMB" target="_blank" rel="noopener noreferrer">来自 Apex<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的 FusedLAMB 优化器的纯 pytorch 变体，在使用 PyTorch XLA 时与 TPU 兼容</li> <li><strong>AdaBelief</strong>：<a href="https://arxiv.org/abs/2010.07468" target="_blank" rel="noopener noreferrer">在本文中<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>有描述。<a href="https://github.com/juntang-zhuang/Adabelief-Optimizer#quick-guide" target="_blank" rel="noopener noreferrer">此处<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>提供有关设置超参数的指南<a href="https://github.com/juntang-zhuang/Adabelief-Optimizer#quick-guide" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>MADGRAD</strong>：<a href="https://arxiv.org/abs/2101.11075" target="_blank" rel="noopener noreferrer">在本文中描述<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>AdaHessian ：</strong> <a href="https://arxiv.org/abs/2006.00719" target="_blank" rel="noopener noreferrer">本文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中描述的自适应二阶优化器<a href="https://arxiv.org/abs/2006.00719" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p><a href="https://pytorch.org/docs/stable/optim.html" target="_blank" rel="noopener noreferrer"><em>timm 中的优化器支持与torch.optim</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>中相同的接口，并且在大多数情况下可以简单地放入训练脚本中而无需进行任何更改。</p> <p>要查看 timm 实现的所有优化器，我们可以检查 timm.optim 模块。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/99d647b8df9edd595deec4649e2ef757.png" alt=""></p> <p>创建优化器的最简单方法是使用<code>create_optimizer_v2</code>工厂函数，它需要以下内容：</p> <ul><li>模型或参数集</li> <li>优化器的名称</li> <li>传递给优化器的任何参数</li></ul> <p>我们可以使用此函数来创建 timm 中包含的任何优化器实现，以及 torch.optim 中流行的优化器和<a href="https://nvidia.github.io/apex/index.html" target="_blank" rel="noopener noreferrer">Apex中的<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><a href="https://nvidia.github.io/apex/optimizers.html" target="_blank" rel="noopener noreferrer">融合优化器<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>（如果已安装）。<a href="https://nvidia.github.io/apex/index.html" target="_blank" rel="noopener noreferrer"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>让我们看一些例子。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/5e0bf05042efa68088ed034812a46f05.png" alt=""></p> <p>在这里，我们可以看到，由于 timm 不包含 SGD 的实现，它使用 torch.optim 的实现创建了我们的优化器。</p> <p>让我们尝试创建一个在 timm 中实现的优化器。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/dcf7f173119a5be680b072758f871e37.png" alt=""></p> <p>我们可以验证<code>Lamb</code>已经使用了 timm 的实现，并且我们的权重衰减已应用于参数组 1。</p> <p><strong>手动创建优化器</strong></p> <p>当然，如果我们不想使用<code>create_optimizer_v2</code>，所有这些优化器都可以用通常的方式创建。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>优化器 = timm.optim.RMSpropTF(model.parameters(), lr=0.01)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="使用示例"><a href="#使用示例" class="header-anchor">#</a> 使用示例</h2> <p>现在，我们可以使用其中的大部分优化器，如下所示：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>_\# 替换  
\# optimizer = torch.optim.Adam(model.parameters(), lr=0.01) \# 用  
_optimizer = timm.optim.AdamP(model.parameters(), lr=0.01) for epoch in num_epochs:   
 for batch in training_dataloader :   
 inputs, targets = batch   
 outputs = model(inputs)   
 loss = loss_function(outputs, targets) loss.backward()  
 优化器.step() 优化器.zero_grad(   
 )
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>在撰写本文时，唯一的例外是二阶<code>Adahessian</code>优化器，它在执行该<code>backward</code>步骤时需要进行一些小的调整；对于将来可能添加的其他二阶优化器，可能需要进行类似的调整。</p> <p>这在下面进行了演示。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>optimizer = timm.optim.Adahessian(model.parameters(), lr=0.01) is\_second\_order = (   
 hasattr(optimizer, **&quot;is\_second\_order&quot;** ) and optimizer.is\_second\_order   
) _\# True_ for epoch in num_epochs:   
 for batch in training_dataloader:   
 inputs, targets =批量  
 输出 = 模型（输入）  
 损失 = 损失函数（输出，目标）损失.向后（创建_图形=第二个顺序）优化器 .step（）  
 优化器.zero_grad（   
 ）
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="展望"><a href="#展望" class="header-anchor">#</a> 展望</h2> <p>timm 还使我们能够将前瞻算法应用于优化器；<a href="https://arxiv.org/abs/1907.08610" target="_blank" rel="noopener noreferrer">在这里介绍并在这里<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>很好<a href="https://www.youtube.com/watch?v=TxGxiDK0Ccc" target="_blank" rel="noopener noreferrer">地解释<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。Lookahead 可以提高学习稳定性并降低其内部优化器的方差，而计算和内存成本可以忽略不计。</p> <p>我们可以通过在优化器名称前加上前缀来将 Lookahead 应用于优化器<code>lookahead_</code>。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>优化器 = timm.optim.create\_optimizer\_v2(model.parameters(), opt='lookahead_adam', lr=0.01)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>或由 timm 的 Lookahead 类中的优化器实例包装：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>timm.optim.Lookahead（优化器，alpha=0.5，k=6）
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>使用 Lookahead 时，我们需要更新我们的训练脚本以包含以下行，以更新慢速权重。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>优化器.sync_lookahead()
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>下面演示了如何使用它的示例：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>optimizer = timm.optim.AdamP(model.parameters(), lr=0.01)   
optimizer = timm.optim.Lookahead(optimizer) for epoch in num_epochs:   
 for batch in training_dataloader:   
 inputs, targets = batch   
 outputs = model(inputs)   
 loss = loss_function(outputs, targets) loss.backward() optimizer.step()   
 optimizer.zero_grad() optimizer.sync_lookahead()
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>在撰写本文时，timm 包含以下调度程序：</p> <ul><li><strong>StepLRScheduler</strong>：学习率每_n_步衰减一次；类似于<a href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" target="_blank" rel="noopener noreferrer">torch.optim.lr_scheduler.StepLR<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>MultiStepLRScheduler</strong>：一个步骤调度器，支持降低学习率的多个里程碑；类似于<a href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR" target="_blank" rel="noopener noreferrer">torch.optim.lr_scheduler.MultiStepLR<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>PlateauLRScheduler</strong>：每次达到指定的指标高原时，将学习率降低一个指定的因子；类似于<a href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau" target="_blank" rel="noopener noreferrer">torch.optim.lr_scheduler.ReduceLROnPlateau<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>CosineLRScheduler</strong>：余弦衰减调度与重启，如<a href="https://arxiv.org/abs/1608.03983" target="_blank" rel="noopener noreferrer">本文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>所述；类似于<a href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts" target="_blank" rel="noopener noreferrer">torch.optim.lr_scheduler.CosineAnnealingWarmRestarts<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>TanhLRScheduler</strong>：带重启的双曲正切衰减时间表，如<a href="https://arxiv.org/abs/1806.01593" target="_blank" rel="noopener noreferrer">本文所述<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>PolyLRScheduler</strong>：多项式衰减时间表，如<a href="https://arxiv.org/abs/2004.05909" target="_blank" rel="noopener noreferrer">本文所述<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>虽然 timm 中实现的许多调度程序在 PyTorch 中都有对应的调度程序，但 timm 版本通常具有不同的默认超参数，并提供额外的选项和灵活性；所有 timm 调度程序预热时期，以及可以选择向计划添加随机噪声。此外，<code>CosineLRScheduler</code>和<code>PolyLRScheduler</code>支持称为_k-decay的衰减选项，如此_<a href="https://arxiv.org/abs/2004.05909" target="_blank" rel="noopener noreferrer">处<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>介绍。</p> <p>在检查这些调度程序提供的一些选项之前，让我们首先探讨如何在自定义训练脚本中使用 timm 的调度程序。</p> <h2 id="使用示例-2"><a href="#使用示例-2" class="header-anchor">#</a> 使用示例</h2> <p>与 PyTorch 中包含的调度程序不同，最好每个时期更新两次 timm 调度程序：</p> <ul><li>该<code>.step_update</code>方法应<strong>在每次优化器更新后</strong>调用，并带有_下一次更新_的索引；这是我们调用<code>.step</code>PyTorch 调度程序的地方</li> <li>该<code>.step</code> 方法应该<strong>在每个纪元结束时</strong>调用，并带有_下一个纪元的索引_</li></ul> <p>通过显式提供更新次数和纪元索引，这使 timm 调度程序能够消除在 PyTorch 调度程序中观察到的令人困惑的“last_epoch”和“-1”行为。</p> <p>下面给出了我们如何使用 timm 调度程序的示例：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>training_epochs = 300   
cooldown_epochs = 10   
num\_epochs = training\_epochs + cooldown_epochs optimizer = timm.optim.AdamP(my_model.parameters(), lr=0.01)   
scheduler = timm.scheduler.CosineLRScheduler(optimizer, t\_initial=training\_epochs)范围内的纪元（num_epochs） : num\_steps\_per\_epoch = len(train\_dataloader)   
 num\_updates = epoch * num\_steps\_per\_epochfor batch in training_dataloader:   
 inputs, targets = batch   
 outputs = model(inputs)   
 loss = loss_function(outputs, targets)loss.backward()   
 optimizer.step()   
 scheduler.step\_update( num\_updates=num_updates) optimizer.zero_grad() scheduler.step（时代+ 1）
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h2 id="调整学习率计划"><a href="#调整学习率计划" class="header-anchor">#</a> 调整学习率计划</h2> <p>为了演示 timm 提供的一些选项，让我们探索一些可用的超参数，以及修改这些参数如何影响学习率计划。</p> <p>在这里，我们将重点关注<code>CosineLRScheduler</code>，因为这是 timm 训练脚本中默认使用的调度程序。然而，如上所述，在上面列出的所有调度程序中都存在诸如添加预热和噪音等功能。</p> <p>为了使学习率计划可视化，让我们定义一个函数来创建模型和优化器以与我们的计划程序一起使用。请注意，由于我们只会更新调度程序，模型实际上并没有被优化，但我们需要一个优化器实例来与我们的调度器一起工作，而优化器需要一个模型。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>def create\_model\_and_optimizer():   
 model = torch.nn.Linear(2, 1)   
 optimizer = torch.optim.SGD(model.parameters(), lr=0.05)  
 返回模型，优化器
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p><strong>使用 PyTorch 的“CosineAnnealingWarmRestarts”调度程序</strong></p> <p>为了说明 timm 的余弦调度器与 PyTorch 中包含的调度器的不同，让我们首先看看我们将如何使用<code>ConsineAnnealingWarmRestarts</code>.</p> <p>此类支持以下参数：</p> <ul><li><strong>T_0</strong> ( <em>int</em> )：第一次重启的迭代次数。</li> <li><strong>T_mult</strong> ( <em>int</em> )：重启后增加_T_{i}的一个因素。_（默认值：`1`）</li> <li><strong>eta_min</strong> ( <em>float</em> ): 最小学习率。（默认值：`0.`）</li> <li><strong>last_epoch</strong> ( <em>int</em> ) — 最后一个纪元的索引。（默认值：<code>-1</code>）</li></ul> <p>要设置我们的时间表，我们需要定义以下内容：epoch 的数量、每个 epoch 发生的更新次数，以及——如果我们想要启用重新启动——学习率应该返回到它的步数初始值。因为我们在这里不使用任何数据，所以我们可以任意设置这些。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>num_epochs=300   
num\_epoch\_repeat = num_epochs//2   
num\_steps\_per_epoch = 10
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>注意</strong>：在这里，我们指定我们希望学习率在训练运行的中途“重新启动”。这主要是出于可视化目的而选择的——这样我们就可以了解这个调度器的重启是什么样子的——而不是在真正的训练运行中推荐使用这个调度器的方式。</p> <p>现在，让我们创建我们的学习率调度器。由于_T_0_需要根据迭代次数指定第一次重启之前的时间——其中每次迭代都是一个批次——我们通过将我们希望重启发生的纪元的索引乘以步数来计算每个时代。在这里，我们还指定学习率不应低于 1e-6。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/d0e5932d6e4524d9966512f7f5f51a56.png" alt=""></p> <p>现在，我们可以在训练循环中模拟使用这个调度程序。由于我们使用的是 PyTorch 实现，我们只需要<code>step</code>在每次优化器更新后调用，每批一次。在这里，我们记录了每一步后的学习率值，这样我们就可以直观地看到在整个训练过程中学习率值是如何调整的。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/1d568d19c5cf6b18fc5c68e64a4b9cdb.png" alt=""></p> <p>从这个图中，我们可以看到学习率一直衰减到第 150 轮，此时它被重置为初始值，然后再次衰减；正如我们所料。</p> <p><strong>使用 timm 的 `CosineLRScheduler` 调度器</strong></p> <p>现在我们了解了如何使用 PyTorch 的余弦调度程序，让我们探讨一下它与 timm 中包含的实现以及提供的其他选项的比较。首先，让我们使用 timm 的余弦学习率调度程序实现来复制之前的情节 — <code>CosineLRScheduler</code>。</p> <p>我们需要这样做的一些参数与我们之前看到的类似：</p> <ul><li><strong>t_initial</strong> ( <em>int</em> ): 第一次重启的迭代次数，相当于torch实现中的T_0</li> <li><strong>lr_min</strong> ( <em>float</em> ): 最小学习率，相当于torch 实现中的<strong>eta_min</strong> (默认: `0.`)</li> <li><strong>cycle_mul</strong> ( <em>float</em> ): 重启后增加_T_{i}_的一个因素，这相当于torch 实现中的<strong>T_mult</strong>（默认值：`1`）</li></ul> <p>然而，为了观察与 Torch 一致的行为，我们还需要设置：</p> <ul><li><strong>cycle_limit</strong> ( <em>int</em> ): 限制一个周期内重启的次数（默认值：`1`）</li> <li><strong>t_in_epochs</strong> ( <em>bool</em> ): 迭代次数是否以纪元而不是批量更新的次数给出（默认值：`True`）</li></ul> <p>首先，让我们定义与之前相同的时间表。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>num_epochs=300   
num\_epoch\_repeat = num_epochs/2   
num\_steps\_per_epoch = 10
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>现在，我们可以创建我们的调度程序实例。在这里，我们用更新步数来表示迭代次数，并将循环限制增加到超过我们期望的重启次数；因此参数与我们之前在 torch 的实现中使用的参数相同。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/a90a8014b07547ff5c2881417de9c9e3.png" alt=""></p> <p>现在，让我们定义一个新函数来模拟在训练运行中使用 timm 调度程序并记录学习率的更新。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>def plot\_lrs\_for\_timm\_scheduler(scheduler): lrs   
 = \[\]for epoch in range(num_epochs):   
 num\_updates = epoch * num\_steps\_per\_epochfor i in range(num\_steps\_per_epoch):   
 num_updates += 1   
 scheduler.step\_update(num\_updates=num_updates) scheduler.step(epoch + 1 ) lrs.append(optimizer.param_groups\[0\]\[ **&quot;lr&quot;** \]) plt.plot(lrs)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>我们现在可以用它来绘制我们的学习率时间表！</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/60cf385ceda21f489c38f2dc3acd6756.png" alt=""></p> <p>正如预期的那样，我们的图表看起来与我们之前看到的相同。</p> <p>现在我们已经复制了我们在 torch 中看到的行为，让我们更详细地看看 timm 提供的一些附加功能。</p> <p>到目前为止，我们已经用优化器更新来表示迭代次数；这要求我们计算第一次重复的迭代次数，<code>num_epoch_repeat * num_steps_per_epoch</code>但是，通过根据纪元指定我们的迭代——这是 timm 中的默认值——我们可以避免必须进行此计算。使用默认设置，我们可以简单地传递我们希望第一次重启发生的纪元索引，如下所示。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/6c4cbcb18ffe8f8a4680166ab8602c68.png" alt=""></p> <p>我们可以看到我们的时间表没有改变，我们只是稍微不同地表达了我们的论点。</p> <p><strong>添加预热和噪音</strong></p> <p>所有 timm 优化器的另一个特点是，它们支持向学习率计划添加预热和噪声。_我们可以使用warmup_t_和_warmup_lr_init_参数指定预热时期的数量，以及预热期间要使用的初始学习率。让我们看看如果我们指定我们想要 20 个预热阶段，我们的时间表会如何变化。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/ac00ed97827ceff6af607041f7f88344.png" alt=""></p> <p>在这里，我们可以看到这导致我们的最小学习率逐渐增加，而不是像我们之前看到的那样从那个点开始。</p> <p>_我们还可以使用noise_range_t_和_noise_pct_参数向一系列时期添加噪声。让我们在前 150 个纪元中添加少量噪声：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/3fb7094842ff6491b83b9055d5db08bf.png" alt=""></p> <p>我们可以看到，直到第 150 轮，添加的噪声会影响我们的时间表，因此学习率不会以平滑的曲线下降。_我们可以通过增加noise_pct_来使其更加极端。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/5dda3e41f04b530e347fcccbecb8d724.png" alt=""></p> <p><strong>`CosineLRScheduler` 的附加选项</strong></p> <p>虽然热身和噪声可以与任何调度程序一起使用，但还有一些特定于<code>CosineLRScheduler</code>. 让我们探讨一下这些如何影响我们的学习率周期。</p> <p>我们可以使用_cycle_mul_来增加下一次重启之前的时间，如下所示。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/50b1af5d752a409755b299becf5ef43f.png" alt=""></p> <p>此外，timm 提供了使用_cycle_limit_限制重启次数的选项。默认情况下，它设置为“1”，这会产生以下计划。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/d9a399022ea59747d47f3771911adc7b.png" alt=""></p> <p><code>CosineLRScheduler</code>还支持不同类型的衰减。我们可以使用_cycle_decay_来减少（或增加）将在每次连续重启期间设置的学习率的值。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/940da38f5479bb28d7e2bf72d3bf7bc6.png" alt=""></p> <p><strong>注意</strong>：这里我们增加了重启次数的频率，以更好地说明衰减。</p> <p>为了控制曲线本身，我们可以使用_k_decay_参数，学习率的变化率由其 k 阶导数改变，如<a href="https://arxiv.org/abs/2004.05909" target="_blank" rel="noopener noreferrer">本文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>所述。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/e1f9102c1e5bac9c1c6d1ea5eaddf18e.png" alt=""></p> <p><img src="https://img-blog.csdnimg.cn/img_convert/1eebd0519d69182c4f8880a09940ce7d.png" alt=""></p> <p>此选项提供了对该调度程序执行的退火的更多控制！</p> <p><strong>timm 训练脚本中的默认设置</strong></p> <p>如果我们使用 timm 训练脚本中的默认设置来设置此调度程序，我们将观察到以下时间表。</p> <p><strong>注意</strong>：在训练脚本中，训练继续进行额外的 10 个时期，而没有进一步修改学习率作为“冷却”。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/6fe16f5e5db2db9b6ca193187f88a434.png" alt=""></p> <p>正如我们所看到的，默认设置根本没有重启！</p> <p><strong>其他学习率时间表</strong></p> <p>虽然我最喜欢 timm 包含的调度程序<code>CosineLRScheduler</code>，但可视化其他一些调度程序的调度可能会有所帮助，这些调度程序在 PyTorch 中没有对应的调度程序。这两个调度器都类似于余弦调度器，因为学习率在指定数量的 epoch 后重置——假设没有设置循环限制——但退火的方式略有不同。</p> <p>对于<code>TanhLRScheduler</code>，使用双曲正切函数执行退火，如下所示。</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/892e76e525715d04d3d53e47f80a367d.png" alt=""></p> <p>timm 还提供<code>PolyLRScheduler</code>，它使用多项式衰减：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/504b22a8f03c367a0a900e48772d9f27.png" alt=""></p> <p>与 类似<code>CosineLRScheduler</code>，<code>PolyLRScheduler</code>调度程序也支持_k_decay_参数，如下所示：</p> <p><img src="https://img-blog.csdnimg.cn/img_convert/cde5b6646c35e60eb61931771243560f.png" alt=""></p> <p><img src="https://img-blog.csdnimg.cn/img_convert/c8a2fe85d7dc3d2e0530b807d964c74f.png" alt=""></p> <p>训练模型时，通过对在整个训练运行中观察到的参数取移动平均值来设置模型权重值可能是有益的，而不是使用上次增量更新后获得的参数。在实践中，这通常是通过维护_EMA 模型_来完成的，该模型是我们正在训练的模型的副本。然而，我们不是在每个更新步骤后更新该模型的所有参数，而是使用现有参数值和更新值的线性组合来设置这些参数。这是使用以下公式完成的：</p> <blockquote><p>updated_EMA_model_weights =</p> <p>衰减 * EMA_model_weights + (1. — 衰减) * updated_model_weights</p></blockquote> <p>其中 _decay_ 是我们设置的参数。例如，如果我们设置_decay=0.99_，我们有：</p> <blockquote><p>updated_EMA_model_weights =</p> <p>0.99 * EMA_model_weights + 0.01 * updated_model_weights</p></blockquote> <p>我们可以看到保留了 99% 的现有状态，只保留了 1% 的新状态！</p> <p>为了理解为什么这可能是有益的，让我们考虑一下我们的模型在训练的早期阶段在一批数据上表现异常糟糕的情况。这可能会导致对我们的参数进行大量更新，过度补偿所获得的高损失，这将对即将到来的批次产生不利影响。通过仅包含一小部分最新参数，大型更新将被“平滑”，并且对模型权重的总体影响较小。</p> <p>有时，这些平均参数有时可以在评估过程中产生明显更好的结果，并且这种技术已被用于多种流行模型的训练方案中，例如训练<a href="https://arxiv.org/abs/1807.11626v3" target="_blank" rel="noopener noreferrer">MNASNet<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>、<a href="https://arxiv.org/abs/1905.02244v5" target="_blank" rel="noopener noreferrer">MobileNet-V3<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>和<a href="https://arxiv.org/abs/1905.11946v5" target="_blank" rel="noopener noreferrer">EfficientNet<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>；使用<a href="https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage" target="_blank" rel="noopener noreferrer">TensorFlow 中包含的实现<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。使用<code>ModelEmaV2</code>timm 中实现的模块，我们可以复制此行为，并将相同的做法应用于我们自己的训练脚本。</p> <p>的实现<code>ModelEmaV2</code>需要以下参数：</p> <ul><li><strong>model</strong>：我们正在训练的_nn.Module的子类。_这是将在我们的训练循环中正常更新的模型</li> <li><strong>decay</strong>：（<em>float</em>）要使用的衰减量，它决定了将保持多少先前的状态。TensorFlow 文档建议衰减的合理值接近 1.0，通常在多个 9 范围内：0.999、0.9999 等（默认值：“0.9999”）</li> <li><strong>device</strong>：应用于评估 EMA 模型的设备。如果未设置，则将在用于模型的同一设备上创建 EMA 模型。</li></ul> <p>让我们探索如何将其纳入训练循环。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>model = create\_model().to(gpu\_device)   
ema_model = ModelEmaV2(model, decay=0.9998) for epoch in num_epochs:   
 for batch in training_dataloader:   
 inputs, targets = batch   
 outputs = model(inputs)   
 loss = loss_function(outputs, targets) 损失.backward()   
 optimizer.step()   
 optimizer.zero_grad() model_ema.update(model) for batch in validation_dataloader:   
 inputs, targets = batch   
 outputs = model(inputs)   
 validation\_loss = loss\_function(outputs, targets) ema\_model\_outputs = model_ema.module(输入）  
 ema\_model\_validation\_loss = loss\_function（ema\_model\_outputs，目标）
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>正如我们所见，要更新 EMA 模型的参数，我们需要<code>.update</code>在每次参数更新后调用。由于 EMA 模型与正在训练的模型有不同的参数，我们必须单独对其进行评估。</p> <p>重要的是要注意这个类对其初始化的位置很敏感。在分布式训练期间，应该在转换为_SyncBatchNorm_之前和使用_DistributedDataParallel_包装器之前应用它！</p> <p>此外，在保存 EMA 模型时，_state_dict_中的键将与正在训练的模型中的键相同，因此应使用不同的检查点！</p> <p>虽然本文中的伪代码片段说明了如何在训练循环中单独使用每个组件，但让我们探索一个我们同时使用许多不同组件的示例！</p> <p>在这里，我们将着眼于在 Imagenette 上训练模型。请注意，由于 Imagenette 是 Imagenet 的一个子集，如果我们使用预训练模型，我们会稍微作弊，因为只有新的分类头会使用随机权重进行初始化；因此，在这个例子中，我们将从头开始训练。</p> <p><strong>注意：</strong> 此示例的目的是演示如何一起使用来自 timm 的多个组件。因此，所选择的特征——以及使用的超参数——在某种程度上是任意选择的；所以通过一些仔细的调整可能会提高性能！</p> <p>要删除我们通常在 PyTorch 训练循环中看到的样板文件，例如遍历 DataLoader 和在设备之间移动数据，我们将使用 PyTorch 加速来处理我们的训练；这使我们能够仅关注使用 timm 组件时所需的差异。</p> <p><em>如果您不熟悉 PyTorch 加速，并且想在深入阅读本文之前了解更多相关信息，请查看</em><a href="https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&amp;sk=868c2d2ec5229fdea42877c0bf82b968" target="_blank" rel="noopener noreferrer"><em>介绍性博客文章</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><em>或</em><a href="https://pytorch-accelerated.readthedocs.io/en/latest/index.html#" target="_blank" rel="noopener noreferrer"><em>文档</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><em>；或者，它非常简单，缺乏这方面的知识不应影响您对此处探讨的内容的理解！</em></p> <p>在 PyTorch 加速中，训练循环由 Trainer 类处理；我们可以在其中覆盖特定方法以更改某些步骤的行为。在伪代码中，在 PyTorch 加速训练器中执行训练可以描述为：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>train_dl =**创建**  
_训练数据 加载**器**（ ）_ **_** _ **_** _        _         _         _ batch_output)         backward\_step(batch\_output\[&quot;loss&quot;\])         optimizer_step()         scheduler_step()         optimizer\_zero\_grad()     train\_epoch\_end()     on\_train\_epoch_end()  
  
  
  
  
      
  
  
  
  
  
  
  
  
 eval\_epoch\_start    ( )   
 on\_eval\_epoch_start        (     )  
    **对于**eval_dl**中**的批处理： _    _     _  
  
  
  
  
  
  

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><p>有关 Trainer 如何工作的更多详细信息，请<a href="https://pytorch-accelerated.readthedocs.io/en/latest/trainer.html#" target="_blank" rel="noopener noreferrer">参阅文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p> <p>我们可以将默认训练器子类化，并在训练脚本中使用它，如下所示：</p> <p>在使用 2 个 GPU 的 Imagenette 上使用这个训练脚本，<a href="https://pytorch-accelerated.readthedocs.io/en/latest/quickstart.html" target="_blank" rel="noopener noreferrer">按照此处的说明<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，我获得了以下指标：</p> <ul><li><em>精度</em>：0.89</li> <li><em>ema_model_accuracy</em>：0.85</li></ul> <p>34 个纪元后；考虑到尚未调整超参数，这还不错！</p> <p>希望这对 timm 中包含的某些功能以及如何将这些功能应用于自定义培训脚本提供了一些全面的概述。</p> <p>最后，我想花点时间感谢 timm 的创建者 Ross Wightman 为创建这个很棒的库所付出的巨大努力。Ross 致力于提供最先进的计算机视觉模型的实现，让整个数据科学界都可以轻松访问这些模型，这是首屈一指的。如果您还没有，请去添加星星！</p> <p><a href="https://gist.github.com/Chris-hughes10/a9e5ec2cd7e7736c651bf89b5484b4a9" target="_blank" rel="noopener noreferrer"><strong>复制这篇文章所需的所有代码都可以在此处</strong><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>作为 GitHub 要点获得。</p> <p><em>Chris Hughes 在</em><a href="http://www.linkedin.com/in/chris-hughes1/" target="_blank" rel="noopener noreferrer"><em>LinkedIn</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><em>上。</em></p> <ul><li><a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">rwightman/pytorch-image-models：PyTorch 图像模型、脚本、预训练权重——ResNet、ResNeXT、EfficientNet、EfficientNetV2、NFNet、Vision Transformer、MixNet、MobileNet-V3/V2、RegNet、DPN、CSPNet 等（github.com） )<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://medium.com/paperswithcode/papers-with-code-2021-a-year-in-review-de75d5a77b8b" target="_blank" rel="noopener noreferrer">代码 2021 论文：回顾一年 | 通过猫王 | 代码论文 | 2021 年 12 月 | 中等的<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://www.image-net.org/" target="_blank" rel="noopener noreferrer">ImageNet (image-net.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://rwightman.github.io/pytorch-image-models/" target="_blank" rel="noopener noreferrer">Pytorch 图像模型 (rwightman.github.io)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://fastai.github.io/timmdocs/" target="_blank" rel="noopener noreferrer">Pytorch 图像模型 (timm) | timmdocs (fastai.github.io)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://paperswithcode.com/lib/timm" target="_blank" rel="noopener noreferrer">PyTorch 图像模型 | 代码论文<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noopener noreferrer">[1812.01187] 使用卷积神经网络进行图像分类的技巧包 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/2010.11929v2" target="_blank" rel="noopener noreferrer">[2010.11929v2] 一幅图像值得 16x16 个单词：用于大规模图像识别的变换器 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://ieeexplore.ieee.org/document/8099589" target="_blank" rel="noopener noreferrer">用于对象检测的特征金字塔网络 | IEEE 会议出版物 | IEEE探索<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://www.robots.ox.ac.uk/~vgg/data/pets/" target="_blank" rel="noopener noreferrer">视觉几何组——牛津大学<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/vision/stable/index.html" target="_blank" rel="noopener noreferrer">torchvision — Torchvision 0.11.0 文档 (pytorch.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/docs/stable/fx.html#module-torch.fx" target="_blank" rel="noopener noreferrer">torch.fx — PyTorch 1.10.1 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/blog/FX-feature-extraction-torchvision/" target="_blank" rel="noopener noreferrer">使用 Torch FX 在 TorchVision 中进行特征提取 | 火炬<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer">TorchScript — PyTorch 1.10.1 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html" target="_blank" rel="noopener noreferrer">TorchScript 简介 — PyTorch Tutorials 1.10.1+cu102 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://onnx.ai/" target="_blank" rel="noopener noreferrer">ONNX | 家<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/docs/master/onnx.html" target="_blank" rel="noopener noreferrer">torch.onnx — PyTorch 大师文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1909.13719" target="_blank" rel="noopener noreferrer">[1909.13719] RandAugment：具有减少搜索空间的实用自动数据扩充（arxiv.org）<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/2110.00476v1#:~:text=ResNet%20strikes%20back%3A%20An%20improved%20training%20procedure%20in,or%20as%20baselines%20when%20new%20architectures%20are%20proposed." target="_blank" rel="noopener noreferrer">[2110.00476v1] ResNet 反击：改进的 timm 训练程序 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1905.04899" target="_blank" rel="noopener noreferrer">[1905.04899] CutMix：训练具有可本地化特征的强分类器的正则化策略 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1710.09412" target="_blank" rel="noopener noreferrer">[1710.09412] 混淆：超越经验风险最小化（arxiv.org）<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/vision/0.11/datasets.html" target="_blank" rel="noopener noreferrer">torchvision.datasets — Torchvision 0.11.0 文档 (pytorch.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://www.tensorflow.org/datasets" target="_blank" rel="noopener noreferrer">TensorFlow 数据集<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/docs/stable/data.html#dataset-types" target="_blank" rel="noopener noreferrer">torch.utils.data — PyTorch 1.10.1 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://docs.python.org/3/library/pathlib.html" target="_blank" rel="noopener noreferrer">pathlib — 面向对象的文件系统路径 — Python 3.10.2 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/docs/stable/optim.html" target="_blank" rel="noopener noreferrer">torch.optim — PyTorch 1.10.1 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/2006.08217" target="_blank" rel="noopener noreferrer">[2006.08217] AdamP：在尺度不变权重上减缓动量优化器的减速 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="noopener noreferrer">lecture_slides_lec6.pdf (toronto.edu)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://nvidia.github.io/apex/index.html" target="_blank" rel="noopener noreferrer">Apex（PyTorch 扩展）— Apex 0.1.0 文档 (nvidia.github.io)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/2010.07468" target="_blank" rel="noopener noreferrer">[2010.07468] AdaBelief 优化器：根据观察到的梯度调整步长 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://github.com/juntang-zhuang/Adabelief-Optimizer#quick-guide" target="_blank" rel="noopener noreferrer">juntang-zhuang/Adabelief-Optimizer：NeurIPS 2020 Spotlight 的存储库“AdaBelief Optimizer：根据观察到的梯度调整步长”(github.com)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/2101.11075" target="_blank" rel="noopener noreferrer">[2101.11075] 不妥协的适应性：一种用于随机优化的动量化、自适应、双平均梯度法 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/2006.00719" target="_blank" rel="noopener noreferrer">[2006.00719] ADAHESSIAN：机器学习的自适应二阶优化器 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1907.08610" target="_blank" rel="noopener noreferrer">[1907.08610] 前瞻优化器：前进 k 步，后退 1 步（arxiv.org）<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://www.youtube.com/watch?v=TxGxiDK0Ccc" target="_blank" rel="noopener noreferrer">前瞻优化器：前进 k 步，后退 1 步 | Michael Zhang——YouTube<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" target="_blank" rel="noopener noreferrer">torch.optim — PyTorch 1.10.1 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1806.01593" target="_blank" rel="noopener noreferrer">[1806.01593] 分类上具有双曲正切衰减的随机梯度下降 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/2004.05909" target="_blank" rel="noopener noreferrer">[2004.05909] k-decay：学习率调度的新方法 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1807.11626v3" target="_blank" rel="noopener noreferrer">[1807.11626v3] MnasNet：面向移动设备的平台感知神经架构搜索 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1905.11946v5" target="_blank" rel="noopener noreferrer">[1905.11946v5] EfficientNet：重新思考卷积神经网络的模型缩放 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://arxiv.org/abs/1905.02244v5" target="_blank" rel="noopener noreferrer">[1905.02244v5] 搜索 MobileNetV3 (arxiv.org)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage" target="_blank" rel="noopener noreferrer">tf.train.指数移动平均 | TensorFlow 核心 v2.7.0<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://towardsdatascience.com/introducing-pytorch-accelerated-6ba99530608c" target="_blank" rel="noopener noreferrer">介绍 PyTorch 加速 | 通过克里斯休斯 | 2021 年 11 月 | 迈向数据科学<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://pytorch-accelerated.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener noreferrer">欢迎使用 pytorch-accelerated 的文档！— pytorch 加速 0.1.3 文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/my-monster/blog/edit/master/docs/01.学术搬砖/02.pytorch学习/05.【转载】PyTorch 图像模型入门 (timm)：从业者指南.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/03/13, 16:17:24</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/bb0c5d/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">torch.matmul()函数用法总结</div></a> <a href="/pages/509e53/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">【转载】灰度图像上的迁移学习：如何微调黑白数据集上的预训练模型</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/bb0c5d/" class="prev">torch.matmul()函数用法总结</a></span> <span class="next"><a href="/pages/509e53/">【转载】灰度图像上的迁移学习：如何微调黑白数据集上的预训练模型</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/e0fcae/"><div>
            为什么深度学习去噪都采用高斯白噪声？
            <!----></div></a> <span class="date">03-13</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/cf75c3/"><div>
            深度学习在图像去噪方面最近有哪些进展，与传统方法相比效果如何？
            <!----></div></a> <span class="date">03-13</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/650608/"><div>
            训练时的学习率调整：optimizer和scheduler - 知乎
            <!----></div></a> <span class="date">03-13</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1335844747@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/my-monster" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=463807063" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2023
    <span>Evan Xu | <a href="https://github.com/my-monster" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.50fadf31.js" defer></script><script src="/assets/js/2.47a03fa1.js" defer></script><script src="/assets/js/3.436c0527.js" defer></script><script src="/assets/js/16.d7372590.js" defer></script>
  </body>
</html>
